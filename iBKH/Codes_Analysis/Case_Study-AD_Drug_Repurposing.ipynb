{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ae0918",
   "metadata": {},
   "source": [
    "# iBKH-based Knowledge Discovery - A Case Study for Drug Repurposing Hypothesis Generation for Alzheimer's Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df2c42",
   "metadata": {},
   "source": [
    "This is the implementation of Alzheimer's Disease (AD) drug repurposing based on iBKH.\n",
    "\n",
    "The task is to dicover drugs that potentially link to AD in the iBKH.\n",
    "\n",
    "Generally, the script contains 3 steps, including: 1) data preparation (triplets generation); 2) knowledge graph embedding learning; and 3)predicting drug entities that potentially link to AD. For convenience, we have preprocessed the raw iBKH data to generate triplet files and trained the knowledge graph embedding models and produced embedding vectors. You may also re-produce them following the steps below.\n",
    "\n",
    "To evaluate model performance, we use the FDA approved and drugs in clinical trials (Phase I, II, III, and IV) for AD treatment as the ground truth.\n",
    "\n",
    "All the input iBKH raw entity & relation files, the intermediate products, i.e., triplet files and embeddings, and the drug list with the ground truth labels, can be downloaded at: https://wcm.box.com/s/jbh90entaed2jotvyab8wjsrprs4i5i8\n",
    "\n",
    "Please make sure putting the downloaded files following the structure below.\n",
    "\n",
    "```\n",
    ".\n",
    "├── ...\n",
    "├── Case Study-AD Drug Repurposing.ipynb\n",
    "├── Data\n",
    "│   ├── iBKH                                 # iBKH raw entity & relation data - INPUT\n",
    "│   │   ├── Entity \n",
    "│   │   ├── Relation\n",
    "│   ├── triplets                             # Extracted triplets \n",
    "│   │   ├── DDi_triplet.csv\n",
    "│   │   ├── DG_triplet.csv\n",
    "│   │   ├── DiG_triplet.csv\n",
    "│   │   ├── GG_triplet.csv\n",
    "│   │   ├── AD_triplets.csv\n",
    "│   ├── dataset\n",
    "│   │   ├── training_triplets.tsv            # Extracted triplets in DGL format\n",
    "│   ├── DistMult                             # KG embeddings based on DistMult\n",
    "│   │   ├── entities.tsv \n",
    "│   │   ├── relations.tsv\n",
    "│   │   ├── iBKH_DistMult_entity.npy\n",
    "│   │   ├── iBKH_DistMult_relation.npy\n",
    "│   ├── ComplEx                              # KG embeddings based on ComplEx\n",
    "│   │   ├── entities.tsv \n",
    "│   │   ├── relations.tsv\n",
    "│   │   ├── iBKH_ComplEx_entity.npy\n",
    "│   │   ├── iBKH_ComplEx_relation.npy\n",
    "│   ├── TransE_l2                            # KG embeddings based on TransE\n",
    "│   │   ├── entities.tsv \n",
    "│   │   ├── relations.tsv\n",
    "│   │   ├── iBKH_TransE_l2.npy\n",
    "│   │   ├── iBKH_TransE_l2.npy\n",
    "│   ├── TransR                               # KG embeddings based on TransR\n",
    "│   │   ├── entities.tsv \n",
    "│   │   ├── relations.tsv\n",
    "│   │   ├── iBKH_TransR_entity.npy\n",
    "│   │   ├── iBKH_TransR_relation.npy\n",
    "│   ├── Drug_list                            # FDA approved and drugs in clinical trials for AD treatment\n",
    "│   │   ├── drugs_list_approve_phase1234.csv\n",
    "│   │   ├── drugs_list_approve_phase234.csv\n",
    "│   │   ├── drugs_list_approve_phase34.csv\n",
    "│   │   ├── drugs_list_approve_phase4.csv\n",
    "│   │   ├── drugs_list_approve.csv\n",
    "├── predict_result                           # Model performance\n",
    "│   │   ├── roc_figures\n",
    "│   └── ...\n",
    "└── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f771c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as fn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfeb80",
   "metadata": {},
   "source": [
    "### Step 1:  Generate Triplet Set from iBKH "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffb333",
   "metadata": {},
   "source": [
    "A triplet, i.e., (h, r, t), is the basic unit for a knowledge graph. We generate triplet set from iBKH, which will be used for knowledge graph embedding learning. Of note, in this drug repurposing case study, we only use triplets among gene, disease, and drug entities in iBKH, due to that: 1) involving all information in iBKH will lead to ~50M triplets, which will cause massive computational cost; 2) underlying indication information of drugs are likely to be captured by the context inforamtion of the drug, diese, gene entities in the KG. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_folder = 'Data/iBKH/' # The folder is used to store the iBKH results, include Entity results and Relation results\n",
    "triplet_path = 'Data/triplets/' # The folder is used to store processed results\n",
    "if not os.path.exists(triplet_path):\n",
    "    os.makedirs(triplet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7671cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug and disease entities\n",
    "\n",
    "def DDi_triplets(): \n",
    "    ddi = pd.read_csv(kg_folder + 'Relation/D_Di_res.csv')\n",
    "\n",
    "    ddi_treats = ddi[ddi['Treats'] == 1]\n",
    "    ddi_treats['Relation'] = ['Treats_DDi'] * len(ddi_treats)\n",
    "    ddi_treats = ddi_treats[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_palliates = ddi[ddi['Palliates'] == 1]\n",
    "    ddi_palliates['Relation'] = ['Palliates_DDi'] * len(ddi_palliates)\n",
    "    ddi_palliates = ddi_palliates[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_effect = ddi[ddi['Effect'] == 1]\n",
    "    ddi_effect['Relation'] = ['Effect_DDi'] * len(ddi_effect)\n",
    "    ddi_effect = ddi_effect[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_associate = ddi[ddi['Associate'] == 1]\n",
    "    ddi_associate['Relation'] = ['Associate_DDi'] * len(ddi_associate)\n",
    "    ddi_associate = ddi_associate[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_IR = ddi[ddi['Inferred_Relation'] == 1]\n",
    "    ddi_IR['Relation'] = ['Inferred_Relation_DDi'] * len(ddi_IR)\n",
    "    ddi_IR = ddi_IR[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_SR = ddi[\n",
    "        (ddi['treatment/therapy (including investigatory)'] == 1) | (ddi['inhibits cell growth (esp. cancers)'] == 1) |\n",
    "        (ddi['alleviates, reduces'] == 1) | (ddi['biomarkers (of disease progression)'] == 1) |\n",
    "        (ddi['prevents, suppresses'] == 1) | (ddi['role in disease pathogenesis'] == 1)]\n",
    "    ddi_SR['Relation'] = ['Semantic_Relation_DDi'] * len(ddi_SR)\n",
    "    ddi_SR = ddi_SR[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_res = pd.concat((ddi_treats, ddi_palliates, ddi_effect, ddi_associate, ddi_IR, ddi_SR))\n",
    "    ddi_res = ddi_res.rename(columns={'Drug': 'Head', 'Disease': 'Tail'})\n",
    "\n",
    "    ddi_res.loc[ddi_res['Relation'] != 'Inferred_Relation_DDi', 'Inference_Score'] = np.nan\n",
    "\n",
    "    ddi_res.to_csv('Data/triplets/DDi_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0aaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug and gene entities.\n",
    "\n",
    "def DG_triplets():\n",
    "    dg = pd.read_csv(kg_folder + 'Relation/D_G_res.csv')\n",
    "\n",
    "    dg_target = dg[dg['Target'] == 1]\n",
    "    dg_target['Relation'] = ['Target_DG'] * len(dg_target)\n",
    "    dg_target['Inference_Score'] = [''] * len(dg_target)\n",
    "    dg_target = dg_target[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_transporter = dg[dg['Transporter'] == 1]\n",
    "    dg_transporter['Relation'] = ['Transporter_DG'] * len(dg_transporter)\n",
    "    dg_transporter['Inference_Score'] = [''] * len(dg_transporter)\n",
    "    dg_transporter = dg_transporter[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_enzyme = dg[dg['Enzyme'] == 1]\n",
    "    dg_enzyme['Relation'] = ['Enzyme_DG'] * len(dg_enzyme)\n",
    "    dg_enzyme['Inference_Score'] = [''] * len(dg_enzyme)\n",
    "    dg_enzyme = dg_enzyme[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_carrier = dg[dg['Carrier'] == 1]\n",
    "    dg_carrier['Relation'] = ['Carrier_DG'] * len(dg_carrier)\n",
    "    dg_carrier['Inference_Score'] = [''] * len(dg_carrier)\n",
    "    dg_carrier = dg_carrier[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_downregulates = dg[dg['Downregulates'] == 1]\n",
    "    dg_downregulates['Relation'] = ['Downregulates_DG'] * len(dg_downregulates)\n",
    "    dg_downregulates['Inference_Score'] = [''] * len(dg_downregulates)\n",
    "    dg_downregulates = dg_downregulates[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_upregulates = dg[dg['Upregulates'] == 1]\n",
    "    dg_upregulates['Relation'] = ['Upregulates_DG'] * len(dg_upregulates)\n",
    "    dg_upregulates['Inference_Score'] = [''] * len(dg_upregulates)\n",
    "    dg_upregulates = dg_downregulates[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_associate = dg[dg['Associate'] == 1]\n",
    "    dg_associate['Relation'] = ['Associate_DG'] * len(dg_associate)\n",
    "    dg_associate['Inference_Score'] = [''] * len(dg_associate)\n",
    "    dg_associate = dg_associate[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_binds = dg[dg['Binds'] == 1]\n",
    "    dg_binds['Relation'] = ['Binds_DG'] * len(dg_binds)\n",
    "    dg_binds['Inference_Score'] = [''] * len(dg_binds)\n",
    "    dg_binds = dg_binds[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_interaction = dg[dg['Interaction'] == 1]\n",
    "    dg_interaction['Relation'] = ['Interaction_DG'] * len(dg_interaction)\n",
    "    dg_interaction['Inference_Score'] = [''] * len(dg_interaction)\n",
    "    dg_interaction = dg_interaction[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_SR = dg[(dg['affects expression/production (neutral)'] == 1) | (dg['agonism, activation'] == 1) |\n",
    "               (dg['inhibits'] == 1) | (dg['metabolism, pharmacokinetics'] == 1) | (dg['antagonism, blocking'] == 1) |\n",
    "               (dg['increases expression/production'] == 1) | (dg['binding, ligand (esp. receptors)'] == 1) |\n",
    "               (dg['decreases expression/production'] == 1) | (dg['transport, channels'] == 1) |\n",
    "               (dg['enzyme activity'] == 1) | (dg['physical association'] == 1)]\n",
    "    dg_SR['Relation'] = ['Semantic_Relation_DG'] * len(dg_SR)\n",
    "    dg_SR['Inference_Score'] = [''] * len(dg_SR)\n",
    "    dg_SR = dg_SR[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_res = pd.concat(\n",
    "        (dg_target, dg_transporter, dg_enzyme, dg_carrier, dg_downregulates, dg_upregulates, dg_associate,\n",
    "         dg_binds, dg_interaction, dg_SR))\n",
    "    dg_res = dg_res.rename(columns={'Drug': 'Head', 'Gene': 'Tail'})\n",
    "\n",
    "    dg_res.to_csv('Data/triplets/DG_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between disease and gene entities.\n",
    "\n",
    "def DiG_triplets():\n",
    "    dig = pd.read_csv(kg_folder + 'Relation/Di_G_res.csv')\n",
    "\n",
    "    dig_associate = dig[dig['Associate'] == 1]\n",
    "    dig_associate['Relation'] = ['Associate_DiG'] * len(dig_associate)\n",
    "    dig_associate = dig_associate[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_downregulates = dig[dig['Downregulates'] == 1]\n",
    "    dig_downregulates['Relation'] = ['Downregulates_DiG'] * len(dig_downregulates)\n",
    "    dig_downregulates = dig_downregulates[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_upregulates = dig[dig['Upregulates'] == 1]\n",
    "    dig_upregulates['Relation'] = ['Upregulates_DiG'] * len(dig_upregulates)\n",
    "    dig_upregulates = dig_upregulates[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_IR = dig[dig['Inferred_Relation'] == 1]\n",
    "    dig_IR['Relation'] = ['Inferred_Relation_DiG'] * len(dig_IR)\n",
    "    dig_IR = dig_IR[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_SR = dig[(dig['improper regulation linked to disease'] == 1) | (dig['causal mutations'] == 1) |\n",
    "                 (dig['polymorphisms alter risk'] == 1) | (dig['role in pathogenesis'] == 1) |\n",
    "                 (dig['possible therapeutic effect'] == 1) | (dig['biomarkers (diagnostic)'] == 1) |\n",
    "                 (dig['promotes progression'] == 1) | (dig['drug targets'] == 1) | (\n",
    "                         dig['overexpression in disease'] == 1) |\n",
    "                 (dig['mutations affecting disease course'] == 1)]\n",
    "    dig_SR['Relation'] = ['Semantic_Relation_DiG'] * len(dig_SR)\n",
    "    dig_SR = dig_SR[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_res = pd.concat((dig_associate, dig_downregulates, dig_upregulates, dig_IR, dig_SR))\n",
    "    dig_res = dig_res.rename(columns={'Disease': 'Head', 'Gene': 'Tail'})\n",
    "\n",
    "    dig_res.loc[dig_res['Relation'] != 'Inferred_Relation_DiG', 'Inference_Score'] = np.nan\n",
    "\n",
    "    dig_res.to_csv('Data/triplets/DiG_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between gene entities.\n",
    "\n",
    "def GG_triplets():\n",
    "    gg = pd.read_csv(kg_folder + 'Relation/G_G_res.csv')\n",
    "\n",
    "    gg_covaries = gg[gg['Covaries'] == 1]\n",
    "    gg_covaries['Relation'] = ['Covaries_GG'] * len(gg_covaries)\n",
    "    gg_covaries['Inference_Score'] = [''] * len(gg_covaries)\n",
    "    gg_covaries = gg_covaries[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_interacts = gg[gg['Interacts'] == 1]\n",
    "    gg_interacts['Relation'] = ['Interacts_GG'] * len(gg_interacts)\n",
    "    gg_interacts['Inference_Score'] = [''] * len(gg_interacts)\n",
    "    gg_interacts = gg_interacts[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_regulates = gg[gg['Regulates'] == 1]\n",
    "    gg_regulates['Relation'] = ['Regulates_GG'] * len(gg_regulates)\n",
    "    gg_regulates['Inference_Score'] = [''] * len(gg_regulates)\n",
    "    gg_regulates = gg_regulates[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_associate = gg[gg['Associate'] == 1]\n",
    "    gg_associate['Relation'] = ['Associate_GG'] * len(gg_associate)\n",
    "    gg_associate['Inference_Score'] = [''] * len(gg_associate)\n",
    "    gg_associate = gg_associate[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_SR = gg[\n",
    "        (gg['activates, stimulates'] == 1) | (gg['production by cell population'] == 1) | (gg['regulation'] == 1) |\n",
    "        (gg['binding, ligand (esp. receptors)'] == 1) | (gg['signaling pathway'] == 1) |\n",
    "        (gg['increases expression/production'] == 1) | (gg['same protein or complex'] == 1) |\n",
    "        (gg['enhances response'] == 1) | (gg['affects expression/production (neutral)'] == 1) |\n",
    "        (gg['physical association'] == 1) | (gg['association'] == 1) | (gg['colocalization'] == 1) |\n",
    "        (gg['dephosphorylation reaction'] == 1) | (gg['cleavage reaction'] == 1) | (gg['direct interation'] == 1) |\n",
    "        (gg['ADP ribosylation reaction'] == 1) | (gg['ubiquitination reaction'] == 1) |\n",
    "        (gg['phosphorylation reaction'] == 1) | (gg['protein cleavage'] == 1)]\n",
    "    gg_SR['Relation'] = ['Semantic_Relation_GG'] * len(gg_SR)\n",
    "    gg_SR['Inference_Score'] = [''] * len(gg_SR)\n",
    "    gg_SR = gg_SR[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_res = pd.concat((gg_covaries, gg_interacts, gg_regulates, gg_associate, gg_SR))\n",
    "    gg_res = gg_res.rename(columns={'Gene_1': 'Head', 'Gene_2': 'Tail'})\n",
    "\n",
    "    gg_res.to_csv('Data/triplets/GG_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718070f3",
   "metadata": {},
   "source": [
    "Run functions to generate corresponding triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDi_triplets()\n",
    "DG_triplets()\n",
    "DiG_triplets()\n",
    "GG_triplets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecfe54",
   "metadata": {},
   "source": [
    "This is an AD (Alzheimer's disease) drug repurposing task, to avoid information leaking in model training, we removed all AD-related triplets from the Drug-Disease triplet set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cee453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a csv file, which combines all triplets for interest with removing \n",
    "# AD-related drug-disease triplets\n",
    "\n",
    "def generate_training_set():\n",
    "    disease_vocab = pd.read_csv(kg_folder + 'Entity/disease_vocab.csv')\n",
    "    AD_related_list = [] # Find AD related entities from the Disease vocabulary in iBKH\n",
    "    for i in range(len(disease_vocab)):\n",
    "        primary_id = disease_vocab.loc[i, 'primary']\n",
    "        disease_name = disease_vocab.loc[i, 'name']\n",
    "        disease_name = disease_name if not pd.isnull(disease_name) else ''\n",
    "        if 'alzheimer' in disease_name:\n",
    "            if primary_id not in AD_related_list:\n",
    "                AD_related_list.append(primary_id)\n",
    "\n",
    "    triplet_folder = 'Data/triplets/'\n",
    "    DDi_triplet = pd.read_csv(triplet_folder + 'DDi_triplet.csv')\n",
    "    DDi_triplet = DDi_triplet[~(DDi_triplet['Tail'].isin(AD_related_list))]\n",
    "    DDi_triplet = DDi_triplet.reset_index(drop=True)\n",
    "    DG_triplet = pd.read_csv(triplet_folder + 'DG_triplet.csv')\n",
    "    DiG_triplet = pd.read_csv(triplet_folder + 'DiG_triplet.csv')\n",
    "    GG_triplet = pd.read_csv(triplet_folder + 'GG_triplet.csv')\n",
    "    DD_triplet = pd.read_csv(triplet_folder + 'DD_triplet.csv')\n",
    "\n",
    "    triplet_set = pd.concat((DDi_triplet, DG_triplet, DiG_triplet, GG_triplet, DD_triplet))\n",
    "    triplet_set = triplet_set[['Head', 'Relation', 'Tail']]\n",
    "\n",
    "    triplet_set.to_csv(triplet_folder + 'training_triplets.csv', index=False)\n",
    "\n",
    "generate_training_set()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fe6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts the triplet csv file to tsv format, according to DGL requirment\n",
    "\n",
    "def generate_training_set():\n",
    "    triplets_set = pd.read_csv(triplet_folder + 'training_triplets.csv')\n",
    "\n",
    "    triples = triplets_set.values.tolist()\n",
    "    train_set = np.arange(len(triples)).tolist()\n",
    "    \n",
    "    dataset_path = 'Data/dataset/'\n",
    "    if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "    print(len(triples), len(train_set))\n",
    "    with open(dataset_path + \"training_triplets.tsv\", 'w+') as f:\n",
    "        for idx in train_set:\n",
    "            f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "            \n",
    "generate_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8550865",
   "metadata": {},
   "source": [
    "### Step 2:  Knowledge graph embedding based on the triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6dee0",
   "metadata": {},
   "source": [
    "We directly invoke the command line toolkit provided by DGL-KE to learn the embedding of entities and relations in iBKH. Here, we use four different models to learn the entity and edge representations of iBKH, namely TransE, TransR, DistMult, and ComplEx. To use other KGE model or AWS instances please refer to DGL-KE’s <a href=\"https://aws-dglke.readthedocs.io/en/latest/index.html\" target=\"_blank\">Document</a>.\n",
    "\n",
    "\n",
    "Of note, for convenience, we have trained the knowledge graph embedding models and produced the embedding vectors which can be found in the downloaded folder. You may also run the command below to reproduce the embedding vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7ebd4",
   "metadata": {},
   "source": [
    "##### TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cffb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplets.tsv --format raw_udd_hrt --model_name TransE_l2 --batch_size 1024 --neg_sample_size 256 --hidden_dim 200 --gamma 12.0 --lr 0.1 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3db1c",
   "metadata": {},
   "source": [
    "##### TransR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812dff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplets.tsv --format raw_udd_hrt --model_name TransR --batch_size 1024 --neg_sample_size 256 --hidden_dim 200 --gamma 12.0 --lr 0.005 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006c62d",
   "metadata": {},
   "source": [
    "##### DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplets.tsv --format raw_udd_hrt --model_name DistMult --batch_size 1024 --neg_sample_size 256 --hidden_dim 400 --gamma 12.0 --lr 0.005 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca016b41",
   "metadata": {},
   "source": [
    "##### ComplEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplets.tsv --format raw_udd_hrt --model_name ComplEx --batch_size 1024 --neg_sample_size 256 --hidden_dim 200 --gamma 12.0 --lr 0.05 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea62fcf",
   "metadata": {},
   "source": [
    "### Step 3: Link prediction for AD drug repurposing hypothesis generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3e457",
   "metadata": {},
   "source": [
    "Inspired by https://www.dgl.ai/news/2020/06/09/covid.html, we used the following algorithms to calculate the edge scores. And the edge scores indicate the strength of association between candidate entities and AD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transE_l2(head, rel, tail, gamma=12.0):\n",
    "    # Paper link: https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "    score = head + rel - tail\n",
    "    \n",
    "    return gamma - th.norm(score, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transR(head, rel, tail, proj, rel_idx, gamma=12.0):\n",
    "    # Paper link: https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9571/9523\n",
    "    proj = proj.reshape(-1, head.shape[1], rel.shape[0])[rel_idx]\n",
    "    head_r = th.einsum('ab,bc->ac', head, proj)\n",
    "    tail_r = th.einsum('b,bc->c', th.tensor(tail), proj)\n",
    "    score = head_r + rel - tail_r\n",
    "    \n",
    "    return gamma - th.norm(score, p=1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistMult(head, rel, tail):\n",
    "    # Paper link: https://arxiv.org/abs/1412.6575\n",
    "    score = head * rel * tail\n",
    "    \n",
    "    return th.sum(score, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complEx(head, rel, tail, gamma=12.0):\n",
    "    # Paper link: https://arxiv.org/abs/1606.06357\n",
    "    real_head, img_head = th.chunk(head, 2, dim=-1)\n",
    "    real_tail, img_tail = th.chunk(th.tensor(tail), 2, dim=-1)\n",
    "    real_rel, img_rel = th.chunk(rel, 2, dim=-1)\n",
    "\n",
    "    score = real_head * real_tail * real_rel \\\n",
    "            + img_head * img_tail * real_rel \\\n",
    "            + real_head * img_tail * img_rel \\\n",
    "            - img_head * real_tail * img_rel\n",
    "\n",
    "    return th.sum(score, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce060d",
   "metadata": {},
   "source": [
    "Below we define the AD_drugs_possibility_prediction function, which generates a prediction score for each drug, indicating the probablity that the drug can be used to treat AD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Data/'\n",
    "Drug_list_folder = 'Data/Drug_list/'\n",
    "kg_folder = 'Data/iBKH/'\n",
    "result_folder = 'predict_result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ee5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AD_drugs_possibility_prediction(model_name, trial_status):\n",
    "    entity_df = pd.read_table(folder + model_name + '/entities.tsv', header=None)\n",
    "    entity_df = entity_df.dropna().reset_index(drop=True)\n",
    "    approved_drug_df = pd.read_csv(Drug_list_folder + 'drugs_list_' + trial_status + '.csv')\n",
    "    approved_drug_list = list(approved_drug_df['Drug'])\n",
    "\n",
    "    entity_map = {}\n",
    "    entity_id_map = {}\n",
    "    relation_map = {}\n",
    "    drug_ids = []\n",
    "    drug_names = []\n",
    "    disease_ids = []\n",
    "\n",
    "    for i in range(len(entity_df)):\n",
    "        entity_id = entity_df.loc[i, 0]\n",
    "        entity_name = entity_df.loc[i, 1]\n",
    "        entity_map[entity_name] = int(entity_id)\n",
    "        entity_id_map[int(entity_id)] = entity_name\n",
    "        if entity_name.replace('DrugBank:', '') in approved_drug_list:\n",
    "            drug_ids.append(entity_id)\n",
    "            drug_names.append(entity_name.replace('DrugBank:', ''))\n",
    "\n",
    "    disease_vocab = pd.read_csv(kg_folder + 'Entity/disease_vocab.csv')\n",
    "    AD_related_list = []\n",
    "    for i in range(len(disease_vocab)):\n",
    "        primary_id = disease_vocab.loc[i, 'primary']\n",
    "        disease_name = disease_vocab.loc[i, 'name']\n",
    "        disease_name = disease_name if not pd.isnull(disease_name) else ''\n",
    "        if 'alzheimer' in disease_name:\n",
    "            if primary_id not in AD_related_list:\n",
    "                AD_related_list.append(primary_id)\n",
    "\n",
    "    relation_df = pd.read_table(folder + model_name + '/relations.tsv', header=None)\n",
    "    for i in range(len(relation_df)):\n",
    "        relation_id = relation_df.loc[i, 0]\n",
    "        relation_name = relation_df.loc[i, 1]\n",
    "        relation_map[relation_name] = int(relation_id)\n",
    "\n",
    "    for disease in AD_related_list:\n",
    "        if disease in entity_map:\n",
    "            disease_ids.append(entity_map[disease])\n",
    "\n",
    "    entity_emb = np.load(folder + model_name + '/iBKH_' + model_name + '_entity.npy')\n",
    "    rel_emb = np.load(folder + model_name + '/iBKH_' + model_name + '_relation.npy')\n",
    "    if model_name == 'TransR':\n",
    "        proj_np = np.load(folder + 'TransR/iBKH_TransRprojection.npy')\n",
    "        proj_emb = th.tensor(proj_np)\n",
    "\n",
    "    treatment = ['Treats_DDi', 'Palliates_DDi', 'Effect_DDi', 'Associate_DDi', 'Inferred_Relation_DDi',\n",
    "                 'Semantic_Relation_DDi']\n",
    "    treatment_rid = [relation_map[treat] for treat in treatment]\n",
    "\n",
    "    drug_ids = th.tensor(drug_ids).long()\n",
    "    disease_ids = th.tensor(disease_ids).long()\n",
    "    treatment_rid = th.tensor(treatment_rid)\n",
    "\n",
    "    drug_emb = th.tensor(entity_emb[drug_ids])\n",
    "    treatment_embs = [th.tensor(rel_emb[rid]) for rid in treatment_rid]\n",
    "\n",
    "    scores_per_disease = []\n",
    "    dids = []\n",
    "    for rid in range(len(treatment_embs)):\n",
    "        treatment_emb = treatment_embs[rid]\n",
    "        for disease_id in disease_ids:\n",
    "            disease_emb = th.tensor(entity_emb[disease_id])\n",
    "            if model_name == 'RotatE':\n",
    "                score = fn.logsigmoid(rotatE(drug_emb, treatment_emb, disease_emb))\n",
    "            elif model_name == 'ComplEx':\n",
    "                score = fn.logsigmoid(complEx(drug_emb, treatment_emb, disease_emb))\n",
    "            elif model_name == 'TransR':\n",
    "                score = fn.logsigmoid(transR(drug_emb, treatment_emb, disease_emb, proj_emb, treatment_rid[rid]))\n",
    "            elif model_name == 'TransE_l2':\n",
    "                score = fn.logsigmoid(transE_l2(drug_emb, treatment_emb, disease_emb))\n",
    "            elif model_name == 'DistMult':\n",
    "                score = fn.logsigmoid(DistMult(drug_emb, treatment_emb, disease_emb))\n",
    "            scores_per_disease.append(score)\n",
    "            dids.append(drug_ids)\n",
    "    scores = th.cat(scores_per_disease)\n",
    "    dids = th.cat(dids)\n",
    "\n",
    "    idx = th.flip(th.argsort(scores), dims=[0])\n",
    "    scores = scores[idx].numpy()\n",
    "    dids = dids[idx].numpy()\n",
    "\n",
    "    _, unique_indices = np.unique(dids, return_index=True)\n",
    "    topk_indices = np.sort(unique_indices)\n",
    "    proposed_dids = dids[topk_indices]\n",
    "    proposed_scores = scores[topk_indices]\n",
    "\n",
    "    candidate_drug_rank = []\n",
    "    candidate_drug_score = {}\n",
    "    for i, idx in enumerate(proposed_dids):\n",
    "        candidate_drug_rank.append(entity_id_map[int(idx)].replace('DrugBank:', ''))\n",
    "        candidate_drug_score[entity_id_map[int(idx)].replace('DrugBank:', '')] = proposed_scores[i]\n",
    "\n",
    "    df = pd.DataFrame(columns=['Drug', 'Score'])\n",
    "    idx = 0\n",
    "    for drug in candidate_drug_score:\n",
    "        df.loc[idx] = [drug, candidate_drug_score[drug]]\n",
    "        idx += 1\n",
    "\n",
    "    x = np.asarray(df['Score']).reshape(-1, 1)  # returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df['Score_scaled'] = pd.DataFrame(x_scaled)\n",
    "    print(df)\n",
    "    df.to_csv(result_folder + \"predict_result_scaled_\" + model_name + \"_\" + trial_status + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8026b4",
   "metadata": {},
   "source": [
    "We propose an ensemble model, which combines the results based on TransE, TransR, DistMult, and complEx to claculate a combined score for each drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0405d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(trial_status):\n",
    "    transE_res = pd.read_csv(result_folder + \"predict_result_scaled_TransE_l2_\" + trial_status + \".csv\")['Drug'].tolist()\n",
    "    transR_res = pd.read_csv(result_folder + \"predict_result_scaled_TransR_\" + trial_status + \".csv\")['Drug'].tolist()\n",
    "    complEx_res = pd.read_csv(result_folder + \"predict_result_scaled_ComplEx_\" + trial_status + \".csv\")['Drug'].tolist()\n",
    "    distMult_res = pd.read_csv(result_folder + \"predict_result_scaled_DistMult_\" + trial_status + \".csv\")['Drug'].tolist()\n",
    "\n",
    "    res = pd.DataFrame(columns=['Drug', 'vote_score'])\n",
    "    idx = 0\n",
    "    for drug in transE_res:\n",
    "        vote_transE = len(transE_res) - transE_res.index(drug)\n",
    "        vote_transR = len(transR_res) - transR_res.index(drug)\n",
    "        vote_complEx = len(complEx_res) - complEx_res.index(drug)\n",
    "        vote_distMult = len(distMult_res) - distMult_res.index(drug)\n",
    "        vote_score = vote_transE + vote_transR + vote_complEx + vote_distMult\n",
    "        res.loc[idx] = [drug, vote_score]\n",
    "        idx += 1\n",
    "    res = res.sort_values('vote_score', ascending=False)\n",
    "    res = res.reset_index(drop=True)\n",
    "    x = np.asarray(res['vote_score']).reshape(-1, 1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    res['Score_scaled'] = pd.DataFrame(x_scaled)\n",
    "    print(res)\n",
    "    res.to_csv(result_folder + \"predict_result_scaled_ensemble_\" + trial_status + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c2b82",
   "metadata": {},
   "source": [
    "#### Model Evaluatoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3288f45",
   "metadata": {},
   "source": [
    "We first downloaded all Food and Drug Administration (FDA) approved drugs and drugs in clinical trials (Phases I-IV) for AD from the DrugBank (https://go.drugbank.com/), constructing the grand truth drug list. Specifically, we obtained a total of 10 FDA-approved drugs, 30 drugs in Phase IV trials, 43 drugs in Phase III trials, 95 drugs in Phase II trials, and 47 drugs in Phase I trials for AD treatment. \n",
    "\n",
    "Of note, to avoid information leaking in prediction, all relations between the AD entity and any drug in the grand truth drug list in the iBKH were removed before calculating entity and relation embedding vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_AUC(model_name):\n",
    "    figures_folder = result_folder + 'roc_figures/'\n",
    "    drug_trial_list = ['approve_phase1234', 'approve_phase234', 'approve_phase34', 'approve_phase4', 'approve']\n",
    "    trial_info = {'approve_phase1234': {'label': 'FDA approved+Phase I~IV', 'color': '#6a4c93'},\n",
    "                  'approve_phase234': {'label': 'FDA approved+Phase II~IV', 'color': '#1982c4'},\n",
    "                  'approve_phase34': {'label': 'FDA approved+Phase III,IV', 'color': '#8ac926'},\n",
    "                  'approve_phase4': {'label': 'FDA approved+Phase IV', 'color': '#ffca3a'},\n",
    "                  'approve': {'label': 'FDA approved', 'color': '#ff595e'}}\n",
    "    plt.figure(figsize=(7, 7))\n",
    "\n",
    "    for trial_status in drug_trial_list:\n",
    "        predict_res = pd.read_csv(result_folder + \"predict_result_scaled_\" + model_name + \"_\" + trial_status + \".csv\")\n",
    "        candidate_df = pd.read_csv(Drug_list_folder + 'drugs_list_' + trial_status + '.csv')\n",
    "\n",
    "        df = pd.merge(predict_res, candidate_df, on='Drug')\n",
    "\n",
    "        label = np.array(list(df['label']))\n",
    "        score = np.array(list(df['Score_scaled']))\n",
    "        # score = np.array(list(df['Score']))\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(label, score)\n",
    "        youden = tpr - fpr\n",
    "        youden_J = np.max(youden)\n",
    "        inds_youden_J = np.where(youden == youden_J)\n",
    "        tpr_max = tpr[inds_youden_J]\n",
    "        fpr_max = fpr[inds_youden_J]\n",
    "        cut_off = thresholds[inds_youden_J][0]\n",
    "        sensitivity = tpr_max[0]\n",
    "        specificity = 1 - fpr_max[0]\n",
    "        prevalence = np.where(label == 1)[0].shape[0] / label.shape[0]\n",
    "        acc = (sensitivity * prevalence) + (specificity * (1 - prevalence))\n",
    "        print(cut_off, sensitivity, specificity, acc)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=trial_info[trial_status]['label'] + ', AUC=' + str(round(auc, 2)),\n",
    "                 color=trial_info[trial_status]['color'])\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', alpha=.8)\n",
    "    plt.tick_params(labelsize=16, bottom=True, left=True)\n",
    "    plt.xlabel(\"1 - Specificity\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"Sensitivity\", fontsize=12, fontweight='bold')\n",
    "    plt.grid(alpha=.3)\n",
    "    plt.legend(prop={'size': 12}, loc=4)\n",
    "    plt.title(model_name, fontweight='bold', fontsize=18)\n",
    "    # plt.show()\n",
    "    plt.savefig(figures_folder + model_name + '.pdf', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try different strategies to build the ground truth AD drug list\n",
    "\n",
    "drug_trial_list = [\n",
    "    'approve_phase1234', # FDA Approved AD drugs + AD drugs in clinical trials Phase I, II, III and IV. \n",
    "    'approve_phase234',  # FDA Approved AD drugs + AD drugs in clinical trials Phase II, III and IV. \n",
    "    'approve_phase34',   # FDA Approved AD drugs + AD drugs in clinical trials Phase III and IV. \n",
    "    'approve_phase4',    # FDA Approved AD drugs + AD drugs in clinical trials Phase IV. \n",
    "    'approve'            # FDA Approved AD drugs only. \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1fe49",
   "metadata": {},
   "source": [
    "##### Prediction & ROC curve (TransE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87465738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'TransE_l2'\n",
    "for trial_status in drug_trial_list:\n",
    "    AD_drugs_possibility_prediction(model_name, trial_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637f37f",
   "metadata": {},
   "source": [
    "##### Prediction & ROC curve (TransR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'TransR'\n",
    "for trial_status in drug_trial_list:\n",
    "    AD_drugs_possibility_prediction(model_name, trial_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5e816",
   "metadata": {},
   "source": [
    "##### Prediction & ROC curve (DistMult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DistMult'\n",
    "for trial_status in drug_trial_list:\n",
    "    AD_drugs_possibility_prediction(model_name, trial_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26008297",
   "metadata": {},
   "source": [
    "##### Prediction & ROC curve (ComplEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ComplEx'\n",
    "for trial_status in drug_trial_list:\n",
    "    AD_drugs_possibility_prediction(model_name, trial_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1fc329",
   "metadata": {},
   "source": [
    "##### Prediction & ROC curve (Ensemble Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_status in drug_trial_list:\n",
    "    ensemble_model(trial_status)\n",
    "\n",
    "generate_AUC('ensemble')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
