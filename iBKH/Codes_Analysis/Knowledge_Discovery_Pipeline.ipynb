{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iBKH-based Knowledge Discovery Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of Knowledge Discovery pipeline in our iBKH portal at http://ibkh.ai/.\n",
    "\n",
    "Given a target entity of interest, the task is to discover the Top-N entities from different entity types (currently supporting gene, drug, symptom, and pathway entities) that potentially link to the target entity. \n",
    "\n",
    "\n",
    "Generally, the script contains 3 steps, including: 1) data preparation (triplets generation); 2) knowledge graph embedding learning; and 3)link prediction for knowledge discovery. For convenience, we have preprocessed the raw iBKH data to generate triplet files and trained the knowledge graph embedding models and produced embedding vectors. You may also re-produce them following the steps below.\n",
    "\n",
    "All the input iBKH raw entity & relation files as well as the intermediate products, i.e., triplet files and embeddings can be downloaded at: https://wcm.box.com/s/1icrjj589nq7kx9bjpdz5sisxl3keerj\n",
    "\n",
    "Please make sure putting the downloaded files following the structure below.\n",
    "\n",
    "```\n",
    ".\n",
    "├── ...\n",
    "├── Knowledge Discovery.ipynb\n",
    "├── Data\n",
    "│   ├── iBKH                             # iBKH raw entity & relation data - INPUT\n",
    "│   │   ├── Entity \n",
    "│   │   ├── Relation\n",
    "│   ├── triplets                         # Extracted triplets \n",
    "│   │   ├── DDi_triplet.csv\n",
    "│   │   ├── DG_triplet.csv\n",
    "│   │   ├── DD_triplet.csv\n",
    "│   │   ├── DPwy_triplet.csv\n",
    "│   │   ├── DSE_triplet.csv\n",
    "│   │   ├── DiDi_triplet.csv\n",
    "│   │   ├── DiG_triplet.csv\n",
    "│   │   ├── DiPwy_triplet.csv\n",
    "│   │   ├── DiSy_triplet.csv\n",
    "│   │   ├── GG_triplet.csv\n",
    "│   │   ├── GPwy_triplet.csv\n",
    "│   │   ├── triplet_whole.csv\n",
    "│   ├── dataset\n",
    "│   │   ├── training_triplet_whole.tsv   # Extracted triplets in DGL format\n",
    "│   ├── UI_emb                           # KG embeddings \n",
    "│   │   ├── entities.tsv \n",
    "│   │   ├── relations.tsv\n",
    "│   │   ├── DistMult                             \n",
    "│   │   │   ├── iBKH_DistMult_entity.npy\n",
    "│   │   │   ├── iBKH_DistMult_relation.npy\n",
    "│   │   ├── ComplEx\n",
    "│   │   │   ├── iBKH_ComplEx_entity.npy\n",
    "│   │   │   ├── iBKH_ComplEx_relation.npy\n",
    "│   │   ├── TransE_l2         \n",
    "│   │   │   ├── iBKH_TransE_l2.npy\n",
    "│   │   │   ├── iBKH_TransE_l2.npy\n",
    "│   │   ├── TransR\n",
    "│   │   │   ├── iBKH_TransR_entity.npy\n",
    "│   │   │   ├── iBKH_TransR_relation.npy\n",
    "│   └── ...\n",
    "└── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Generate Triplet Set from iBKH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A triplet, i.e., (h, r, t), is the basic unit for a knowledge graph. We generate triplet set from iBKH, which will be used for knowledge graph embedding learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_folder = 'Data/iBKH/' # The folder is used to store the iBKH results, include Entity results and Relation results\n",
    "triplet_path = 'Data/triplets/' # The folder is used to store processed results\n",
    "if not os.path.exists(triplet_path):\n",
    "    os.makedirs(triplet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug and disease entities\n",
    "\n",
    "def DDi_triplets(): \n",
    "    ddi = pd.read_csv(kg_folder + 'Relation/D_Di_res.csv')\n",
    "\n",
    "    ddi_treats = ddi[ddi['Treats'] == 1]\n",
    "    ddi_treats['Relation'] = ['Treats_DDi'] * len(ddi_treats)\n",
    "    ddi_treats = ddi_treats[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_palliates = ddi[ddi['Palliates'] == 1]\n",
    "    ddi_palliates['Relation'] = ['Palliates_DDi'] * len(ddi_palliates)\n",
    "    ddi_palliates = ddi_palliates[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_effect = ddi[ddi['Effect'] == 1]\n",
    "    ddi_effect['Relation'] = ['Effect_DDi'] * len(ddi_effect)\n",
    "    ddi_effect = ddi_effect[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_associate = ddi[ddi['Associate'] == 1]\n",
    "    ddi_associate['Relation'] = ['Associate_DDi'] * len(ddi_associate)\n",
    "    ddi_associate = ddi_associate[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_IR = ddi[ddi['Inferred_Relation'] == 1]\n",
    "    ddi_IR['Relation'] = ['Inferred_Relation_DDi'] * len(ddi_IR)\n",
    "    ddi_IR = ddi_IR[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_SR = ddi[\n",
    "        (ddi['treatment/therapy (including investigatory)'] == 1) | (ddi['inhibits cell growth (esp. cancers)'] == 1) |\n",
    "        (ddi['alleviates, reduces'] == 1) | (ddi['biomarkers (of disease progression)'] == 1) |\n",
    "        (ddi['prevents, suppresses'] == 1) | (ddi['role in disease pathogenesis'] == 1)]\n",
    "    ddi_SR['Relation'] = ['Semantic_Relation_DDi'] * len(ddi_SR)\n",
    "    ddi_SR = ddi_SR[['Drug', 'Relation', 'Disease', 'Inference_Score']]\n",
    "\n",
    "    ddi_res = pd.concat((ddi_treats, ddi_palliates, ddi_effect, ddi_associate, ddi_IR, ddi_SR))\n",
    "    ddi_res = ddi_res.rename(columns={'Drug': 'Head', 'Disease': 'Tail'})\n",
    "\n",
    "    ddi_res.loc[ddi_res['Relation'] != 'Inferred_Relation_DDi', 'Inference_Score'] = np.nan\n",
    "\n",
    "    ddi_res.to_csv('Data/triplets/DDi_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug and gene entities.\n",
    "\n",
    "def DG_triplets():\n",
    "    dg = pd.read_csv(kg_folder + 'Relation/D_G_res.csv')\n",
    "\n",
    "    dg_target = dg[dg['Target'] == 1]\n",
    "    dg_target['Relation'] = ['Target_DG'] * len(dg_target)\n",
    "    dg_target['Inference_Score'] = [''] * len(dg_target)\n",
    "    dg_target = dg_target[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_transporter = dg[dg['Transporter'] == 1]\n",
    "    dg_transporter['Relation'] = ['Transporter_DG'] * len(dg_transporter)\n",
    "    dg_transporter['Inference_Score'] = [''] * len(dg_transporter)\n",
    "    dg_transporter = dg_transporter[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_enzyme = dg[dg['Enzyme'] == 1]\n",
    "    dg_enzyme['Relation'] = ['Enzyme_DG'] * len(dg_enzyme)\n",
    "    dg_enzyme['Inference_Score'] = [''] * len(dg_enzyme)\n",
    "    dg_enzyme = dg_enzyme[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_carrier = dg[dg['Carrier'] == 1]\n",
    "    dg_carrier['Relation'] = ['Carrier_DG'] * len(dg_carrier)\n",
    "    dg_carrier['Inference_Score'] = [''] * len(dg_carrier)\n",
    "    dg_carrier = dg_carrier[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_downregulates = dg[dg['Downregulates'] == 1]\n",
    "    dg_downregulates['Relation'] = ['Downregulates_DG'] * len(dg_downregulates)\n",
    "    dg_downregulates['Inference_Score'] = [''] * len(dg_downregulates)\n",
    "    dg_downregulates = dg_downregulates[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_upregulates = dg[dg['Upregulates'] == 1]\n",
    "    dg_upregulates['Relation'] = ['Upregulates_DG'] * len(dg_upregulates)\n",
    "    dg_upregulates['Inference_Score'] = [''] * len(dg_upregulates)\n",
    "    dg_upregulates = dg_downregulates[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_associate = dg[dg['Associate'] == 1]\n",
    "    dg_associate['Relation'] = ['Associate_DG'] * len(dg_associate)\n",
    "    dg_associate['Inference_Score'] = [''] * len(dg_associate)\n",
    "    dg_associate = dg_associate[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_binds = dg[dg['Binds'] == 1]\n",
    "    dg_binds['Relation'] = ['Binds_DG'] * len(dg_binds)\n",
    "    dg_binds['Inference_Score'] = [''] * len(dg_binds)\n",
    "    dg_binds = dg_binds[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_interaction = dg[dg['Interaction'] == 1]\n",
    "    dg_interaction['Relation'] = ['Interaction_DG'] * len(dg_interaction)\n",
    "    dg_interaction['Inference_Score'] = [''] * len(dg_interaction)\n",
    "    dg_interaction = dg_interaction[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_SR = dg[(dg['affects expression/production (neutral)'] == 1) | (dg['agonism, activation'] == 1) |\n",
    "               (dg['inhibits'] == 1) | (dg['metabolism, pharmacokinetics'] == 1) | (dg['antagonism, blocking'] == 1) |\n",
    "               (dg['increases expression/production'] == 1) | (dg['binding, ligand (esp. receptors)'] == 1) |\n",
    "               (dg['decreases expression/production'] == 1) | (dg['transport, channels'] == 1) |\n",
    "               (dg['enzyme activity'] == 1) | (dg['physical association'] == 1)]\n",
    "    dg_SR['Relation'] = ['Semantic_Relation_DG'] * len(dg_SR)\n",
    "    dg_SR['Inference_Score'] = [''] * len(dg_SR)\n",
    "    dg_SR = dg_SR[['Drug', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dg_res = pd.concat(\n",
    "        (dg_target, dg_transporter, dg_enzyme, dg_carrier, dg_downregulates, dg_upregulates, dg_associate,\n",
    "         dg_binds, dg_interaction, dg_SR))\n",
    "    dg_res = dg_res.rename(columns={'Drug': 'Head', 'Gene': 'Tail'})\n",
    "\n",
    "    dg_res.to_csv('Data/triplets/DG_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug entities.\n",
    "\n",
    "def DD_triplets():\n",
    "    dd = pd.read_csv(kg_folder + 'Relation/D_D_res.csv')\n",
    "\n",
    "    dd_interaction = dd[dd['Interaction'] == 1]\n",
    "    dd_interaction['Relation'] = ['Interaction_DD'] * len(dd_interaction)\n",
    "    dd_interaction['Inference_Score'] = [''] * len(dd_interaction)\n",
    "    dd_interaction = dd_interaction[['Drug_1', 'Relation', 'Drug_2', 'Inference_Score']]\n",
    "\n",
    "    dd_resemble = dd[dd['Resemble'] == 1]\n",
    "    dd_resemble['Relation'] = ['Resemble_DD'] * len(dd_resemble)\n",
    "    dd_resemble['Inference_Score'] = [''] * len(dd_resemble)\n",
    "    dd_resemble = dd_resemble[['Drug_1', 'Relation', 'Drug_2', 'Inference_Score']]\n",
    "\n",
    "    dd_res = pd.concat((dd_interaction, dd_resemble))\n",
    "    dd_res = dd_res.rename(columns={'Drug_1': 'Head', 'Drug_2': 'Tail'})\n",
    "\n",
    "    dd_res.to_csv('Data/triplets/DD_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug and pathway entities.\n",
    "\n",
    "def DPwy_triplets():\n",
    "    dpwy = pd.read_csv(kg_folder + 'Relation/D_Pwy_res.csv')\n",
    "\n",
    "    dpwy['Relation'] = ['Association_DPwy'] * len(dpwy)\n",
    "    dpwy['Inference_Score'] = [''] * len(dpwy)\n",
    "    dpwy_res = dpwy[['Drug', 'Relation', 'Pathway', 'Inference_Score']]\n",
    "    dpwy_res = dpwy_res.rename(columns={'Drug': 'Head', 'Pathway': 'Tail'})\n",
    "\n",
    "    dpwy_res.to_csv('Data/triplets/DPwy_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between drug and side-effect entities.\n",
    "\n",
    "def DSE_triplets():\n",
    "    dse = pd.read_csv(kg_folder + 'Relation/D_SE_res.csv')\n",
    "\n",
    "    dse['Relation'] = ['Cause_DSE'] * len(dse)\n",
    "    dse['Inference_Score'] = [''] * len(dse)\n",
    "    dse_res = dse[['Drug', 'Relation', 'Side_Effect', 'Inference_Score']]\n",
    "    dse_res = dse_res.rename(columns={'Drug': 'Head', 'Side_Effect': 'Tail'})\n",
    "\n",
    "    dse_res.to_csv('Data/triplets/DSE_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between disease entities.\n",
    "\n",
    "def DiDi_triplets():\n",
    "    didi = pd.read_csv(kg_folder + 'Relation/Di_Di_res.csv')\n",
    "\n",
    "    didi_is_a = didi[didi['is_a'] == 1]\n",
    "    didi_is_a['Relation'] = ['is_a_DiDi'] * len(didi_is_a)\n",
    "    didi_is_a['Inference_Score'] = [''] * len(didi_is_a)\n",
    "    didi_is_a = didi_is_a[['Disease_1', 'Relation', 'Disease_2', 'Inference_Score']]\n",
    "\n",
    "    didi_resemble = didi[didi['Resemble'] == 1]\n",
    "    didi_resemble['Relation'] = ['Resemble_DiDi'] * len(didi_resemble)\n",
    "    didi_resemble['Inference_Score'] = [''] * len(didi_resemble)\n",
    "    didi_resemble = didi_resemble[['Disease_1', 'Relation', 'Disease_2', 'Inference_Score']]\n",
    "\n",
    "    didi_res = pd.concat((didi_is_a, didi_resemble))\n",
    "    didi_res = didi_res.rename(columns={'Disease_1': 'Head', 'Disease_2': 'Tail'})\n",
    "\n",
    "    didi_res.to_csv('Data/triplets/DiDi_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between disease and gene entities.\n",
    "\n",
    "def DiG_triplets():\n",
    "    dig = pd.read_csv(kg_folder + 'Relation/Di_G_res.csv')\n",
    "\n",
    "    dig_associate = dig[dig['Associate'] == 1]\n",
    "    dig_associate['Relation'] = ['Associate_DiG'] * len(dig_associate)\n",
    "    dig_associate = dig_associate[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_downregulates = dig[dig['Downregulates'] == 1]\n",
    "    dig_downregulates['Relation'] = ['Downregulates_DiG'] * len(dig_downregulates)\n",
    "    dig_downregulates = dig_downregulates[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_upregulates = dig[dig['Upregulates'] == 1]\n",
    "    dig_upregulates['Relation'] = ['Upregulates_DiG'] * len(dig_upregulates)\n",
    "    dig_upregulates = dig_upregulates[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_IR = dig[dig['Inferred_Relation'] == 1]\n",
    "    dig_IR['Relation'] = ['Inferred_Relation_DiG'] * len(dig_IR)\n",
    "    dig_IR = dig_IR[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_SR = dig[(dig['improper regulation linked to disease'] == 1) | (dig['causal mutations'] == 1) |\n",
    "                 (dig['polymorphisms alter risk'] == 1) | (dig['role in pathogenesis'] == 1) |\n",
    "                 (dig['possible therapeutic effect'] == 1) | (dig['biomarkers (diagnostic)'] == 1) |\n",
    "                 (dig['promotes progression'] == 1) | (dig['drug targets'] == 1) | (\n",
    "                         dig['overexpression in disease'] == 1) |\n",
    "                 (dig['mutations affecting disease course'] == 1)]\n",
    "    dig_SR['Relation'] = ['Semantic_Relation_DiG'] * len(dig_SR)\n",
    "    dig_SR = dig_SR[['Disease', 'Relation', 'Gene', 'Inference_Score']]\n",
    "\n",
    "    dig_res = pd.concat((dig_associate, dig_downregulates, dig_upregulates, dig_IR, dig_SR))\n",
    "    dig_res = dig_res.rename(columns={'Disease': 'Head', 'Gene': 'Tail'})\n",
    "\n",
    "    dig_res.loc[dig_res['Relation'] != 'Inferred_Relation_DiG', 'Inference_Score'] = np.nan\n",
    "\n",
    "    dig_res.to_csv('Data/triplets/DiG_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between disease and pathway entities.\n",
    "\n",
    "def DiPwy_triplets():\n",
    "    dipwy = pd.read_csv(kg_folder + 'Relation/Di_Pwy_res.csv')\n",
    "\n",
    "    dipwy['Relation'] = ['Association_DiPwy'] * len(dipwy)\n",
    "    dipwy['Inference_Score'] = [''] * len(dipwy)\n",
    "    dipwy_res = dipwy[['Disease', 'Relation', 'Pathway', 'Inference_Score']]\n",
    "    dipwy_res = dipwy_res.rename(columns={'Disease': 'Head', 'Pathway': 'Tail'})\n",
    "\n",
    "    dipwy_res.to_csv('Data/triplets/DiPwy_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between disease and symptom entities.\n",
    "\n",
    "def DiSy_triplets():\n",
    "    disy = pd.read_csv(kg_folder + 'Relation/Di_Sy_res.csv')\n",
    "\n",
    "    disy['Relation'] = ['Present_DiSy'] * len(disy)\n",
    "    disy['Inference_Score'] = [''] * len(disy)\n",
    "    disy_res = disy[['Disease', 'Relation', 'Symptom', 'Inference_Score']]\n",
    "    disy_res = disy_res.rename(columns={'Disease': 'Head', 'Symptom': 'Tail'})\n",
    "\n",
    "    disy_res.to_csv('Data/triplets/DiSy_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between gene entities.\n",
    "\n",
    "def GG_triplets():\n",
    "    gg = pd.read_csv(kg_folder + 'Relation/G_G_res.csv')\n",
    "\n",
    "    gg_covaries = gg[gg['Covaries'] == 1]\n",
    "    gg_covaries['Relation'] = ['Covaries_GG'] * len(gg_covaries)\n",
    "    gg_covaries['Inference_Score'] = [''] * len(gg_covaries)\n",
    "    gg_covaries = gg_covaries[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_interacts = gg[gg['Interacts'] == 1]\n",
    "    gg_interacts['Relation'] = ['Interacts_GG'] * len(gg_interacts)\n",
    "    gg_interacts['Inference_Score'] = [''] * len(gg_interacts)\n",
    "    gg_interacts = gg_interacts[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_regulates = gg[gg['Regulates'] == 1]\n",
    "    gg_regulates['Relation'] = ['Regulates_GG'] * len(gg_regulates)\n",
    "    gg_regulates['Inference_Score'] = [''] * len(gg_regulates)\n",
    "    gg_regulates = gg_regulates[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_associate = gg[gg['Associate'] == 1]\n",
    "    gg_associate['Relation'] = ['Associate_GG'] * len(gg_associate)\n",
    "    gg_associate['Inference_Score'] = [''] * len(gg_associate)\n",
    "    gg_associate = gg_associate[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_SR = gg[\n",
    "        (gg['activates, stimulates'] == 1) | (gg['production by cell population'] == 1) | (gg['regulation'] == 1) |\n",
    "        (gg['binding, ligand (esp. receptors)'] == 1) | (gg['signaling pathway'] == 1) |\n",
    "        (gg['increases expression/production'] == 1) | (gg['same protein or complex'] == 1) |\n",
    "        (gg['enhances response'] == 1) | (gg['affects expression/production (neutral)'] == 1) |\n",
    "        (gg['physical association'] == 1) | (gg['association'] == 1) | (gg['colocalization'] == 1) |\n",
    "        (gg['dephosphorylation reaction'] == 1) | (gg['cleavage reaction'] == 1) | (gg['direct interation'] == 1) |\n",
    "        (gg['ADP ribosylation reaction'] == 1) | (gg['ubiquitination reaction'] == 1) |\n",
    "        (gg['phosphorylation reaction'] == 1) | (gg['protein cleavage'] == 1)]\n",
    "    gg_SR['Relation'] = ['Semantic_Relation_GG'] * len(gg_SR)\n",
    "    gg_SR['Inference_Score'] = [''] * len(gg_SR)\n",
    "    gg_SR = gg_SR[['Gene_1', 'Relation', 'Gene_2', 'Inference_Score']]\n",
    "\n",
    "    gg_res = pd.concat((gg_covaries, gg_interacts, gg_regulates, gg_associate, gg_SR))\n",
    "    gg_res = gg_res.rename(columns={'Gene_1': 'Head', 'Gene_2': 'Tail'})\n",
    "\n",
    "    gg_res.to_csv('Data/triplets/GG_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting triplets between gene and pathway entities.\n",
    "\n",
    "def GPwy_triplets():\n",
    "    gpwy = pd.read_csv(kg_folder + 'Relation/G_Pwy_res.csv')\n",
    "\n",
    "    gpwy['Relation'] = ['Associate_GPwy'] * len(gpwy)\n",
    "    gpwy['Inference_Score'] = [''] * len(gpwy)\n",
    "    gpwy_res = gpwy[['Gene', 'Relation', 'Pathway', 'Inference_Score']]\n",
    "    gpwy_res = gpwy_res.rename(columns={'Gene': 'Head', 'Pathway': 'Tail'})\n",
    "\n",
    "    gpwy_res.to_csv('Data/triplets/GPwy_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run functions to generate corresponding triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDi_triplets()\n",
    "DG_triplets()\n",
    "DPwy_triplets()\n",
    "DSE_triplets()\n",
    "DiDi_triplets()\n",
    "DiG_triplets()\n",
    "DiPwy_triplets()\n",
    "DiSy_triplets()\n",
    "GG_triplets()\n",
    "GPwy_triplets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the triplets set extracting from the relation results among the entities, then convert the triplet set from .csv format to the .tsv format based on the DGL input requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a csv file, which combines all triplets extracted from the above functions.\n",
    "\n",
    "def generate_triplet_set():\n",
    "    DDi_triplet = pd.read_csv('Data/triplets/DDi_triplet.csv')\n",
    "    DiG_triplet = pd.read_csv('Data/triplets/DiG_triplet.csv')\n",
    "    DG_triplet = pd.read_csv('Data/triplets/DG_triplet.csv')\n",
    "    GG_triplet = pd.read_csv('Data/triplets/GG_triplet.csv')\n",
    "    DD_triplet = pd.read_csv('Data/triplets/DD_triplet.csv')\n",
    "    DiDi_triplet = pd.read_csv('Data/triplets/DiDi_triplet.csv')\n",
    "    GPwy_triplet = pd.read_csv('Data/triplets/GPwy_triplet.csv')\n",
    "    DiPwy_triplet = pd.read_csv('Data/triplets/DiPwy_triplet.csv')\n",
    "    DPwy_triplet = pd.read_csv('Data/triplets/DPwy_triplet.csv')\n",
    "    DiSy_triplet = pd.read_csv('Data/triplets/DiSy_triplet.csv')\n",
    "    DSE_triplet = pd.read_csv('Data/triplets/DSE_triplet.csv')\n",
    "\n",
    "    triplet_set = pd.concat((DDi_triplet, DG_triplet, DiG_triplet, GG_triplet, DD_triplet, DiDi_triplet, GPwy_triplet,\n",
    "                             DPwy_triplet, DiPwy_triplet, DiSy_triplet, DSE_triplet))\n",
    "    triplet_set = triplet_set[['Head', 'Relation', 'Tail']]\n",
    "\n",
    "    triplet_set.to_csv('Data/triplets/triplet_whole.csv', index=False)\n",
    "\n",
    "generate_triplet_set()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts the triplet csv file to tsv format, according to DGL requirment\n",
    "\n",
    "def generate_training_set():\n",
    "    triplets_set = pd.read_csv('Data/triplets/triplet_whole.csv')\n",
    "\n",
    "    triples = triplets_set.values.tolist()\n",
    "    train_set = np.arange(len(triples)).tolist()\n",
    "    \n",
    "    dataset_path = 'Data/dataset/'\n",
    "    if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "    print(len(triples), len(train_set))\n",
    "    with open(\"Data/dataset/training_triplet_whole.tsv\", 'w+') as f:\n",
    "        for idx in train_set:\n",
    "            f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "            \n",
    "generate_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Knowledge graph embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We directly invoke the command line toolkit provided by DGL-KE to learn the embedding of entities and relations in iBKH. Here, we use four different models to learn the entity and edge representations of iBKH, namely TransE, TransR, DistMult, and ComplEx. To use other KGE model or AWS instances please refer to DGL-KE’s <a href=\"https://aws-dglke.readthedocs.io/en/latest/index.html\" target=\"_blank\">Document</a>.\n",
    "\n",
    "\n",
    "Of note, for convenience, we have trained the knowledge graph embedding models and produced the embedding vectors which can be found in the downloaded folder. You may also run the command below to reproduce the embedding vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplet_whole.tsv --format raw_udd_hrt --model_name TransE_l2 --batch_size 3000 --neg_sample_size 256 --hidden_dim 400 --gamma 12.0 --lr 0.1 --max_step 50000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-09 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TransR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplet_whole.tsv --format raw_udd_hrt --model_name TransR --batch_size 1024 --neg_sample_size 256 --hidden_dim 200 --gamma 12.0 --lr 0.005 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplet_whole.tsv --format raw_udd_hrt --model_name DistMult --batch_size 1024 --neg_sample_size 256 --hidden_dim 400 --gamma 12.0 --lr 0.005 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ComplEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGLBACKEND=pytorch dglke_train --dataset iBKH --data_path ./dataset --data_files training_triplet_whole.tsv --format raw_udd_hrt --model_name ComplEx --batch_size 1024 --neg_sample_size 256 --hidden_dim 200 --gamma 12.0 --lr 0.05 --max_step 10000 --log_interval 100 --batch_size_eval 1000 -adv --regularization_coef 1.00E-07 --num_thread 1 --num_proc 8 --neg_sample_size_eval 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Knowledge Discovery on iBKH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by https://www.dgl.ai/news/2020/06/09/covid.html, we used the following algorithms to calculate the edge scores. And the edge scores indicate the strength of association between candidate entities and queried entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transE_l2(head, rel, tail, gamma=12.0):\n",
    "    # Paper link: https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "    score = head + rel - tail\n",
    "    \n",
    "    return gamma - th.norm(score, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transR(head, rel, tail, proj, rel_idx, gamma=12.0):\n",
    "    # Paper link: https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9571/9523\n",
    "    proj = proj.reshape(-1, head.shape[1], rel.shape[0])[rel_idx]\n",
    "    head_r = th.einsum('ab,bc->ac', head, proj)\n",
    "    tail_r = th.einsum('b,bc->c', th.tensor(tail), proj)\n",
    "    score = head_r + rel - tail_r\n",
    "    \n",
    "    return gamma - th.norm(score, p=1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistMult(head, rel, tail):\n",
    "    # Paper link: https://arxiv.org/abs/1412.6575\n",
    "    score = head * rel * tail\n",
    "    \n",
    "    return th.sum(score, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complEx(head, rel, tail, gamma=12.0):\n",
    "    # Paper link: https://arxiv.org/abs/1606.06357\n",
    "    real_head, img_head = th.chunk(head, 2, dim=-1)\n",
    "    real_tail, img_tail = th.chunk(th.tensor(tail), 2, dim=-1)\n",
    "    real_rel, img_rel = th.chunk(rel, 2, dim=-1)\n",
    "\n",
    "    score = real_head * real_tail * real_rel \\\n",
    "            + img_head * img_tail * real_rel \\\n",
    "            + real_head * img_tail * img_rel \\\n",
    "            - img_head * real_tail * img_rel\n",
    "\n",
    "    return th.sum(score, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDi = pd.read_csv('Data/triplets/DDi_triplet.csv')\n",
    "DiG = pd.read_csv('Data/triplets/DiG_triplet.csv')\n",
    "DiSy = pd.read_csv('Data/triplets/DiSy_triplet.csv')\n",
    "DiPwy = pd.read_csv('Data/triplets/DiPwy_triplet.csv')\n",
    "DG = pd.read_csv('Data/triplets/DG_triplet.csv')\n",
    "DSE = pd.read_csv('Data/triplets/DSE_triplet.csv')\n",
    "DPwy = pd.read_csv('Data/triplets/DPwy_triplet.csv')\n",
    "GPwy = pd.read_csv('Data/triplets/GPwy_triplet.csv')\n",
    "GG = pd.read_csv('Data/triplets/GG_triplet.csv')\n",
    "DiDi = pd.read_csv('Data/triplets/DiDi_triplet.csv')\n",
    "DD = pd.read_csv('Data/triplets/DD_triplet.csv')\n",
    "\n",
    "drug_vocab = pd.read_csv(kg_folder + 'Entity/drug_vocab.csv')\n",
    "drug_dict = drug_vocab.set_index('primary')['name'].to_dict()\n",
    "drug_name_dict = drug_vocab.set_index('name')['primary'].to_dict()\n",
    "disease_vocab = pd.read_csv(kg_folder + 'Entity/disease_vocab.csv')\n",
    "disease_dict = disease_vocab.set_index('primary')['name'].to_dict()\n",
    "disease_name_dict = disease_vocab.set_index('name')['primary'].to_dict()\n",
    "gene_vocab = pd.read_csv(kg_folder + 'Entity/gene_vocab.csv')\n",
    "gene_dict = gene_vocab.set_index('primary')['symbol'].to_dict()\n",
    "gene_symbol_dict = gene_vocab.set_index('symbol')['primary'].to_dict()\n",
    "symptom_vocab = pd.read_csv(kg_folder + 'Entity/symptom_vocab.csv')\n",
    "symptom_dict = symptom_vocab.set_index('primary')['name'].to_dict()\n",
    "symptom_name_dict = symptom_vocab.set_index('name')['primary'].to_dict()\n",
    "pathway_vocab = pd.read_csv(kg_folder + 'Entity/pathway_vocab.csv')\n",
    "pathway_dict = pathway_vocab.set_index('primary')['name'].to_dict()\n",
    "pathway_name_dict = pathway_vocab.set_index('name')['primary'].to_dict()\n",
    "se_vocab = pd.read_csv(kg_folder + 'Entity/side_effect_vocab.csv')\n",
    "se_dict = se_vocab.set_index('primary')['name'].to_dict()\n",
    "se_name_dict = se_vocab.set_index('name')['primary'].to_dict()\n",
    "\n",
    "# Pre-processing dictionaries to help execute functions\n",
    "\n",
    "with open('Data/entity_map.obj', 'rb') as f:\n",
    "    entity_map = pickle.load(f)\n",
    "f.close()\n",
    "with open('Data/entity_id_map.obj', 'rb') as f:\n",
    "    entity_id_map = pickle.load(f)\n",
    "f.close()\n",
    "with open('Data/relation_map.obj', 'rb') as f:\n",
    "    relation_map = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "entity_emb_TransE = np.load('Data/UI_emb/TransE/iBKH_TransE_l2_entity.npy')\n",
    "rel_emb_TransE = np.load('Data/UI_emb/TransE/iBKH_TransE_l2_relation.npy')\n",
    "\n",
    "entity_emb_TransR = np.load('Data/UI_emb/TransR/iBKH_TransR_entity.npy')\n",
    "rel_emb_TransR = np.load('Data/UI_emb/TransR/iBKH_TransR_relation.npy')\n",
    "proj_np = np.load('Data/UI_emb/TransR/iBKH_TransRprojection.npy')\n",
    "proj_emb = th.tensor(proj_np)\n",
    "\n",
    "entity_emb_ComplEx = np.load('Data/UI_emb/ComplEx/iBKH_ComplEx_entity.npy')\n",
    "rel_emb_ComplEx = np.load('Data/UI_emb/ComplEx/iBKH_ComplEx_relation.npy')\n",
    "\n",
    "entity_emb_DistMult = np.load('Data/UI_emb/DistMult/iBKH_DistMult_entity.npy')\n",
    "rel_emb_DistMult = np.load('Data/UI_emb/DistMult/iBKH_DistMult_relation.npy')\n",
    "\n",
    "entity_df = pd.read_table('Case_Study/UI_emb/entities.tsv', header=None)\n",
    "entity_df = entity_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the ranked results based on edge scores from different embedding data.\n",
    "\n",
    "def rank_result(candidate_ids, rel_ids, target_emb, rel_embs, candidate_emb, model_name, rel_type=None, proj_emb=None):\n",
    "    scores_candidate = []\n",
    "    dids = []\n",
    "    if rel_type == 'GG':\n",
    "        for rid in range(len(rel_embs)):\n",
    "            GG_emb = rel_embs[rid]\n",
    "            if model_name == 'TransE':\n",
    "                score_1 = fn.logsigmoid(transE_l2(candidate_emb, GG_emb, target_emb))\n",
    "                score_2 = fn.logsigmoid(transE_l2(target_emb, GG_emb, candidate_emb))\n",
    "            elif model_name == 'ComplEx':\n",
    "                score_1 = fn.logsigmoid(complEx(candidate_emb, GG_emb, target_emb))\n",
    "                score_2 = fn.logsigmoid(complEx(target_emb, GG_emb, candidate_emb))\n",
    "            elif model_name == 'TransR':\n",
    "                score_1 = fn.logsigmoid(transR(candidate_emb, GG_emb, target_emb, proj_emb, rel_ids[rid]))\n",
    "                score_2 = fn.logsigmoid(transR(candidate_emb, GG_emb, target_emb, proj_emb, rel_ids[rid]))\n",
    "            elif model_name == 'DistMult':\n",
    "                score_1 = fn.logsigmoid(DistMult(candidate_emb, GG_emb, target_emb))\n",
    "                score_2 = fn.logsigmoid(DistMult(target_emb, GG_emb, candidate_emb))\n",
    "            scores_candidate.append(score_1)\n",
    "            scores_candidate.append(score_2)\n",
    "            dids.append(candidate_ids)\n",
    "            dids.append(candidate_ids)\n",
    "    else:\n",
    "        for rid in range(len(rel_embs)):\n",
    "            rel_emb = rel_embs[rid]\n",
    "            if model_name == 'TransE':\n",
    "                score = fn.logsigmoid(transE_l2(candidate_emb, rel_emb, target_emb))\n",
    "            elif model_name == 'ComplEx':\n",
    "                score = fn.logsigmoid(complEx(candidate_emb, rel_emb, target_emb))\n",
    "            elif model_name == 'TransR':\n",
    "                score = fn.logsigmoid(transR(candidate_emb, rel_emb, target_emb, proj_emb, rel_ids[rid]))\n",
    "            elif model_name == 'DistMult':\n",
    "                score = fn.logsigmoid(DistMult(candidate_emb, rel_emb, target_emb))\n",
    "            scores_candidate.append(score)\n",
    "            dids.append(candidate_ids)\n",
    "\n",
    "    scores = th.cat(scores_candidate)\n",
    "    dids = th.cat(dids)\n",
    "\n",
    "    idx = th.flip(th.argsort(scores), dims=[0])\n",
    "    dids = dids[idx].numpy()\n",
    "\n",
    "    _, unique_indices = np.unique(dids, return_index=True)\n",
    "    topk_indices = np.sort(unique_indices)\n",
    "    proposed_dids = dids[topk_indices]\n",
    "\n",
    "    return [entity_id_map[int(idx)] for idx in proposed_dids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose an ensemble model, which combines the results based on TransE, TransR, DistMult, and complEx to claculate a combined score for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(transE_res, transR_res, complEx_res, distMult_res):\n",
    "    res = pd.DataFrame(columns=['Entity', 'vote_score'])\n",
    "    idx = 0\n",
    "    for drug in transE_res:\n",
    "        vote_transE = len(transE_res) - transE_res.index(drug)\n",
    "        vote_transR = len(transR_res) - transR_res.index(drug)\n",
    "        vote_complEx = len(complEx_res) - complEx_res.index(drug)\n",
    "        vote_distMult = len(distMult_res) - distMult_res.index(drug)\n",
    "        vote_score = vote_transE + vote_transR + vote_complEx + vote_distMult\n",
    "        res.loc[idx] = [drug, vote_score]\n",
    "        idx += 1\n",
    "    res = res.sort_values('vote_score', ascending=False)\n",
    "    res = res.reset_index(drop=True)\n",
    "\n",
    "    return res['Entity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the HTML content based on the ranked results.\n",
    "\n",
    "def generate_html(candidate_ids, candidate_type, top_k):\n",
    "    col = ['Rank', 'Type', 'Primary_ID', 'Name', 'Link']\n",
    "    predicted_candidate_df = pd.DataFrame(columns=col)\n",
    "    candidate_ids = candidate_ids[:int(top_k)]\n",
    "    for i, candidate_id in enumerate(candidate_ids):\n",
    "        candidate_name = ''\n",
    "        if candidate_type == 'Drug':\n",
    "            candidate_name = drug_dict[candidate_id]\n",
    "            candidate_link = 'https://go.drugbank.com/drugs/' + candidate_id.replace('DrugBank:', '')\n",
    "            candidate_idx = str(i + 1)\n",
    "        if candidate_type == 'Disease':\n",
    "            candidate_name = disease_dict[candidate_id]\n",
    "            candidate_link = 'https://disease-ontology.org/'\n",
    "            candidate_idx = str(i + 1)\n",
    "        if candidate_type == 'Gene':\n",
    "            candidate_name = gene_dict[candidate_id]\n",
    "            candidate_link = 'https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/' + candidate_id\n",
    "            candidate_idx = str(i + 1)\n",
    "        if candidate_type == 'Symptom':\n",
    "            candidate_name = symptom_dict[candidate_id]\n",
    "            candidate_link = 'https://www.ncbi.nlm.nih.gov/mesh/?term=' + candidate_id.replace('MESH:', '')\n",
    "            candidate_idx = str(i + 1)\n",
    "        if candidate_type == 'Pathway':\n",
    "            candidate_name = pathway_dict[candidate_id]\n",
    "            if 'REACT' in candidate_id:\n",
    "                candidate_link = 'https://reactome.org/content/detail/R-HSA-71403' + candidate_id.replace('REACT:', '')\n",
    "            else:\n",
    "                candidate_link = 'https://www.genome.jp/pathway/' + candidate_id.replace('KEGG:', '')\n",
    "            candidate_idx = str(i + 1)\n",
    "        if candidate_type == 'Side_Effect':\n",
    "            candidate_name = se_dict[candidate_id]\n",
    "            candidate_link = 'http://sideeffects.embl.de/se/' + candidate_id.replace('UMLS:', '')\n",
    "            candidate_idx = str(i + 1)\n",
    "\n",
    "        predicted_candidate_df.loc[i] = [candidate_idx, candidate_type, candidate_id, candidate_name, candidate_link]\n",
    "\n",
    "    html = '<table lay-filter=\"index_table\" lay-size=\"lg\"><thead><tr>'\n",
    "    for col_names in col:\n",
    "        if col_names == 'Link':\n",
    "            html += \"<th lay-data='{field:\\\"\" + col_names + \"\\\", width:380}'>\" + col_names + '</th>'\n",
    "        elif col_names == 'Rank':\n",
    "            html += \"<th lay-data='{field:\\\"\" + col_names + \"\\\", width:80}'>\" + col_names + '</th>'\n",
    "        elif col_names == 'Type':\n",
    "            html += \"<th lay-data='{field:\\\"\" + col_names + \"\\\", width:120}'>\" + col_names + '</th>'\n",
    "        else:\n",
    "            html += \"<th lay-data='{field:\\\"\" + col_names + \"\\\", width:270}'>\" + col_names + '</th>'\n",
    "    html += \"<th lay-data='{field:\\\"Evidence\\\", toolbar:\\\"#barDemo\\\", width:250}'>Evidence</th>\"\n",
    "    html += \"</tr></thead><tbody>\"\n",
    "\n",
    "    for i in range(0, len(predicted_candidate_df)):\n",
    "        html += \"<tr>\"\n",
    "        features = predicted_candidate_df.iloc[i, 0:-1]\n",
    "        for value in features:\n",
    "            html += \"<td>\" + str(value) + \"</td>\"\n",
    "        candidate_link = predicted_candidate_df.iloc[i, -1]\n",
    "        html += \"<td><a href='\" + candidate_link + \"' target='_blank' rel='noopener noreferrer'>\" + candidate_link + \"</a></td>\"\n",
    "        html += \"</tr>\"\n",
    "    html += \"</tbody></table>\"\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_triplets(target_entity, candidate_ids, candidate_type, rel_ids, top_k, rel_type=None):\n",
    "    if target_entity in entity_map:\n",
    "        candidate_emb_transE = th.tensor(entity_emb_TransE[candidate_ids])\n",
    "        rel_embs_transE = [th.tensor(rel_emb_TransE[rid]) for rid in rel_ids]\n",
    "        target_emb_transE = th.tensor(entity_emb_TransE[entity_map[target_entity]])\n",
    "\n",
    "        candidate_emb_TransR = th.tensor(entity_emb_TransR[candidate_ids])\n",
    "        rel_embs_TransR = [th.tensor(rel_emb_TransR[rid]) for rid in rel_ids]\n",
    "        target_emb_TransR = th.tensor(entity_emb_TransR[entity_map[target_entity]])\n",
    "\n",
    "        candidate_emb_ComplEx = th.tensor(entity_emb_ComplEx[candidate_ids])\n",
    "        rel_embs_ComplEx = [th.tensor(rel_emb_ComplEx[rid]) for rid in rel_ids]\n",
    "        target_emb_ComplEx = th.tensor(entity_emb_ComplEx[entity_map[target_entity]])\n",
    "\n",
    "        candidate_emb_DistMult = th.tensor(entity_emb_DistMult[candidate_ids])\n",
    "        rel_embs_DistMult = [th.tensor(rel_emb_DistMult[rid]) for rid in rel_ids]\n",
    "        target_emb_DistMult = th.tensor(entity_emb_DistMult[entity_map[target_entity]])\n",
    "\n",
    "        if rel_type == 'GG':\n",
    "            predict_res_TransE = rank_result(candidate_ids, rel_ids, target_emb_transE, rel_embs_transE,\n",
    "                                             candidate_emb_transE, 'TransE', rel_type='GG')\n",
    "            predict_res_TransR = rank_result(candidate_ids, rel_ids, target_emb_TransR, rel_embs_TransR,\n",
    "                                             candidate_emb_TransR, 'TransR', 'GG', proj_emb)\n",
    "            predict_res_ComplEx = rank_result(candidate_ids, rel_ids, target_emb_ComplEx, rel_embs_ComplEx,\n",
    "                                              candidate_emb_ComplEx, 'ComplEx', rel_type='GG')\n",
    "            predict_res_DistMult = rank_result(candidate_ids, rel_ids, target_emb_DistMult, rel_embs_DistMult,\n",
    "                                               candidate_emb_DistMult, 'DistMult', rel_type='GG')\n",
    "        else:\n",
    "            predict_res_TransE = rank_result(candidate_ids, rel_ids, target_emb_transE, rel_embs_transE, candidate_emb_transE,\n",
    "                                             'TransE')\n",
    "            predict_res_TransR = rank_result(candidate_ids, rel_ids, target_emb_TransR, rel_embs_TransR, candidate_emb_TransR,\n",
    "                                             'TransR', None, proj_emb)\n",
    "            predict_res_ComplEx = rank_result(candidate_ids, rel_ids, target_emb_ComplEx, rel_embs_ComplEx,\n",
    "                                              candidate_emb_ComplEx, 'ComplEx')\n",
    "            predict_res_DistMult = rank_result(candidate_ids, rel_ids, target_emb_DistMult, rel_embs_DistMult,\n",
    "                                               candidate_emb_DistMult, 'DistMult')\n",
    "\n",
    "        ensemble_res = ensemble_model(predict_res_TransE, predict_res_TransR, predict_res_ComplEx, predict_res_DistMult)\n",
    "\n",
    "        html_TransE = generate_html(predict_res_TransE, candidate_type, top_k)\n",
    "        html_TransR = generate_html(predict_res_TransR, candidate_type, top_k)\n",
    "        html_ComplEx = generate_html(predict_res_ComplEx, candidate_type, top_k)\n",
    "        html_DistMult = generate_html(predict_res_DistMult, candidate_type, top_k)\n",
    "        html_ensemble = generate_html(ensemble_res, candidate_type, top_k)\n",
    "    else:\n",
    "        html_ensemble = html_TransE = html_TransR = html_ComplEx = html_DistMult = ''\n",
    "\n",
    "    return html_ensemble, html_TransE, html_TransR, html_ComplEx, html_DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the input target entity, the following function will generate the HTML content, \n",
    "# which will be displayed in our iBKH portal.\n",
    "\n",
    "def generate_predict_res(target_type, entity_name, top_k):\n",
    "    predict_res = {}\n",
    "    if target_type == 'Disease':\n",
    "        target_id = disease_name_dict[entity_name]\n",
    "        drug_tp_df = DDi[DDi['Tail'] == target_id]\n",
    "        drug_tp_list = list(drug_tp_df['Head'])\n",
    "        drug_candidate_df = entity_df[(entity_df[1].str.contains('DrugBank')) & (~entity_df[1].isin(drug_tp_list))]\n",
    "        drug_list = list(drug_candidate_df[1])\n",
    "        DDi_rel = list(DDi.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        drug_ids = [entity_map[d] for d in drug_list]\n",
    "        drug_ids = th.tensor(drug_ids).long()\n",
    "        DDi_ids = [relation_map[rel] for rel in DDi_rel]\n",
    "        DDi_ids = th.tensor(DDi_ids)\n",
    "        html_ensemble_drug, html_TransE_drug, html_TransR_drug, html_ComplEx_drug, html_DistMult_drug = \\\n",
    "            predict_triplets(target_id, drug_ids, 'Drug', DDi_ids, top_k)\n",
    "\n",
    "        gene_tp_df = DiG[DiG['Head'] == target_id]\n",
    "        gene_tp_list = list(gene_tp_df['Tail'])\n",
    "        gene_candidate_df = entity_df[(entity_df[1].str.contains('HGNC')) & (~entity_df[1].isin(gene_tp_list))]\n",
    "        gene_list = list(gene_candidate_df[1])\n",
    "        DiG_rel = list(DiG.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        gene_ids = [entity_map[d] for d in gene_list]\n",
    "        gene_ids = th.tensor(gene_ids).long()\n",
    "        DiG_ids = [relation_map[rel] for rel in DiG_rel]\n",
    "        DiG_ids = th.tensor(DiG_ids)\n",
    "        html_ensemble_gene, html_TransE_gene, html_TransR_gene, html_ComplEx_gene, html_DistMult_gene = \\\n",
    "            predict_triplets(target_id, gene_ids, 'Gene', DiG_ids, top_k)\n",
    "\n",
    "        symptom_tp_df = DiSy[DiSy['Head'] == target_id]\n",
    "        symptom_tp_list = list(symptom_tp_df['Tail'])\n",
    "        symptom_candidate_df = symptom_vocab[~symptom_vocab['primary'].isin(symptom_tp_list)]\n",
    "        symptom_list = list(symptom_candidate_df['primary'])\n",
    "        DiSy_rel = ['Present_DiSy']\n",
    "        symptom_ids = []\n",
    "        for sy in symptom_list:\n",
    "            if sy in entity_map:\n",
    "                symptom_ids.append(entity_map[sy])\n",
    "            else:\n",
    "                continue\n",
    "        symptom_ids = th.tensor(symptom_ids).long()\n",
    "        DiSy_ids = [relation_map[rel] for rel in DiSy_rel]\n",
    "        DiSy_ids = th.tensor(DiSy_ids)\n",
    "        html_ensemble_symptom, html_TransE_symptom, html_TransR_symptom, html_ComplEx_symptom, html_DistMult_symptom = \\\n",
    "            predict_triplets(target_id, symptom_ids, 'Symptom', DiSy_ids, top_k)\n",
    "\n",
    "        pathway_tp_df = DiPwy[DiPwy['Head'] == target_id]\n",
    "        pathway_tp_list = list(pathway_tp_df['Tail'])\n",
    "        pathway_candidate_df = pathway_vocab[~pathway_vocab['primary'].isin(pathway_tp_list)]\n",
    "        pathway_list = list(pathway_candidate_df['primary'])\n",
    "        DiPwy_rel = ['Association_DiPwy']\n",
    "        pathway_ids = []\n",
    "        for pwy in pathway_list:\n",
    "            if pwy in entity_map:\n",
    "                pathway_ids.append(entity_map[pwy])\n",
    "            else:\n",
    "                continue\n",
    "        pathway_ids = th.tensor(pathway_ids).long()\n",
    "        DiPwy_rids = [relation_map[rel] for rel in DiPwy_rel]\n",
    "        DiPwy_rids = th.tensor(DiPwy_rids)\n",
    "        html_ensemble_pathway, html_TransE_pathway, html_TransR_pathway, html_ComplEx_pathway, html_DistMult_pathway = \\\n",
    "            predict_triplets(target_id, pathway_ids, 'Pathway', DiPwy_rids, top_k)\n",
    "\n",
    "        predict_res['Ensemble'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\"+ html_ensemble_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ensemble_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Symptom</h2><div class='layui-colla-content'>\" + html_ensemble_symptom + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_ensemble_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransE'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransE_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransE_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Symptom</h2><div class='layui-colla-content'>\" + html_TransE_symptom + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_TransE_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransR'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransR_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransR_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Symptom</h2><div class='layui-colla-content'>\" + html_TransR_symptom + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_TransR_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['ComplEx'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ComplEx_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ComplEx_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Symptom</h2><div class='layui-colla-content'>\" + html_ComplEx_symptom + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_ComplEx_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['DistMult'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_DistMult_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_DistMult_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Symptom</h2><div class='layui-colla-content'>\" + html_DistMult_symptom + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_DistMult_pathway + \"</div></div></div>\"\n",
    "\n",
    "    elif target_type == 'Drug':\n",
    "        target_id = drug_name_dict[entity_name]\n",
    "        disease_tp_df = DDi[DDi['Head'] == target_id]\n",
    "        disease_tp_list = list(disease_tp_df['Tail'])\n",
    "        disease_candidate_df = entity_df[(entity_df[1].str.contains('DOID')) & (~entity_df[1].isin(disease_tp_list))]\n",
    "        disease_list = list(disease_candidate_df[1])\n",
    "        DDi_rel = list(DDi.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        disease_ids = [entity_map[d] for d in disease_list]\n",
    "        disease_ids = th.tensor(disease_ids).long()\n",
    "        DDi_ids = [relation_map[rel] for rel in DDi_rel]\n",
    "        DDi_ids = th.tensor(DDi_ids)\n",
    "        html_ensemble_disease, html_TransE_disease, html_TransR_disease, html_ComplEx_disease, html_DistMult_disease = \\\n",
    "            predict_triplets(target_id, disease_ids, 'Disease', DDi_ids, top_k)\n",
    "\n",
    "        gene_tp_df = DG[DG['Head'] == target_id]\n",
    "        gene_tp_list = list(gene_tp_df['Tail'])\n",
    "        gene_candidate_df = entity_df[(entity_df[1].str.contains('HGNC')) & (~entity_df[1].isin(gene_tp_list))]\n",
    "        gene_list = list(gene_candidate_df[1])\n",
    "        DG_rel = list(DG.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        gene_ids = [entity_map[g] for g in gene_list]\n",
    "        gene_ids = th.tensor(gene_ids).long()\n",
    "        DG_ids = [relation_map[rel] for rel in DG_rel]\n",
    "        DG_ids = th.tensor(DG_ids)\n",
    "        html_ensemble_gene, html_TransE_gene, html_TransR_gene, html_ComplEx_gene, html_DistMult_gene = \\\n",
    "            predict_triplets(target_id, gene_ids, 'Gene', DG_ids, top_k)\n",
    "\n",
    "        se_tp_df = DSE[DSE['Head'] == target_id]\n",
    "        se_tp_list = list(se_tp_df['Tail'])\n",
    "        se_candidate_df = se_vocab[~se_vocab['primary'].isin(se_tp_list)]\n",
    "        se_list = list(se_candidate_df['primary'])\n",
    "        DSE_rel = ['Cause_DSE']\n",
    "        DSE_ids = [relation_map[rel] for rel in DSE_rel]\n",
    "        DSE_ids = th.tensor(DSE_ids)\n",
    "        se_ids = []\n",
    "        for se in se_list:\n",
    "            if se in entity_map:\n",
    "                se_ids.append(entity_map[se])\n",
    "            else:\n",
    "                continue\n",
    "        se_ids = th.tensor(se_ids).long()\n",
    "        html_ensemble_se, html_TransE_se, html_TransR_se, html_ComplEx_se, html_DistMult_se = \\\n",
    "            predict_triplets(target_id, se_ids, 'Side_Effect', DSE_ids, top_k)\n",
    "\n",
    "        pathway_tp_df = DPwy[DPwy['Head'] == target_id]\n",
    "        pathway_tp_list = list(pathway_tp_df['Tail'])\n",
    "        pathway_candidate_df = pathway_vocab[~pathway_vocab['primary'].isin(pathway_tp_list)]\n",
    "        pathway_list = list(pathway_candidate_df['primary'])\n",
    "        DPwy_rel = ['Association_DiPwy']\n",
    "        DPwy_ids = [relation_map[rel] for rel in DPwy_rel]\n",
    "        pathway_ids = []\n",
    "        for pwy in pathway_list:\n",
    "            if pwy in entity_map:\n",
    "                pathway_ids.append(entity_map[pwy])\n",
    "            else:\n",
    "                continue\n",
    "        pathway_ids = th.tensor(pathway_ids).long()\n",
    "        DPwy_ids = th.tensor(DPwy_ids)\n",
    "        html_ensemble_pathway, html_TransE_pathway, html_TransR_pathway, html_ComplEx_pathway, html_DistMult_pathway = \\\n",
    "            predict_triplets(target_id, pathway_ids, 'Pathway', DPwy_ids, top_k)\n",
    "\n",
    "        predict_res['Ensemble'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ensemble_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ensemble_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Side Effect</h2><div class='layui-colla-content'>\" + html_ensemble_se + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_ensemble_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransE'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransE_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransE_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Side Effect</h2><div class='layui-colla-content'>\" + html_TransE_se + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_TransE_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransR'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransR_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransR_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Side Effect</h2><div class='layui-colla-content'>\" + html_TransR_se + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_TransR_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['ComplEx'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ComplEx_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ComplEx_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Side Effect</h2><div class='layui-colla-content'>\" + html_ComplEx_se + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_ComplEx_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['DistMult'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_DistMult_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_DistMult_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Side Effect</h2><div class='layui-colla-content'>\" + html_DistMult_se + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_DistMult_pathway + \"</div></div></div>\"\n",
    "\n",
    "    elif target_type == 'Gene':\n",
    "        target_id = gene_symbol_dict[entity_name]\n",
    "        disease_tp_df = DiG[DiG['Tail'] == target_id]\n",
    "        disease_tp_list = list(disease_tp_df['Head'])\n",
    "        disease_candidate_df = entity_df[(entity_df[1].str.contains('DOID')) & (~entity_df[1].isin(disease_tp_list))]\n",
    "        disease_list = list(disease_candidate_df[1])\n",
    "        DiG_rel = list(DiG.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        DiG_ids = [relation_map[rel] for rel in DiG_rel]\n",
    "        disease_ids = [entity_map[g] for g in disease_list]\n",
    "        disease_ids = th.tensor(disease_ids).long()\n",
    "        DiG_ids = th.tensor(DiG_ids)\n",
    "        html_ensemble_disease, html_TransE_disease, html_TransR_disease, html_ComplEx_disease, html_DistMult_disease = \\\n",
    "            predict_triplets(target_id, disease_ids, 'Disease', DiG_ids, top_k)\n",
    "\n",
    "        drug_tp_df = DG[DG['Tail'] == target_id]\n",
    "        drug_tp_list = list(drug_tp_df['Head'])\n",
    "        drug_candidate_df = entity_df[(entity_df[1].str.contains('DrugBank')) & (~entity_df[1].isin(drug_tp_list))]\n",
    "        drug_list = list(drug_candidate_df[1])\n",
    "        DG_rel = list(DG.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        DG_ids = [relation_map[rel] for rel in DG_rel]\n",
    "        drug_ids = [entity_map[g] for g in drug_list]\n",
    "        drug_ids = th.tensor(drug_ids).long()\n",
    "        DG_ids = th.tensor(DG_ids)\n",
    "        html_ensemble_drug, html_TransE_drug, html_TransR_drug, html_ComplEx_drug, html_DistMult_drug = \\\n",
    "            predict_triplets(target_id, drug_ids, 'Drug', DG_ids, top_k)\n",
    "\n",
    "        pathway_tp_df = GPwy[GPwy['Head'] == target_id]\n",
    "        pathway_tp_list = list(pathway_tp_df['Tail'])\n",
    "        pathway_candidate_df = pathway_vocab[~pathway_vocab['primary'].isin(pathway_tp_list)]\n",
    "        pathway_list = list(pathway_candidate_df['primary'])\n",
    "        GPwy_rel = ['Association_DiPwy']\n",
    "        GPwy_ids = [relation_map[rel] for rel in GPwy_rel]\n",
    "        pathway_ids = []\n",
    "        for pwy in pathway_list:\n",
    "            if pwy in entity_map:\n",
    "                pathway_ids.append(entity_map[pwy])\n",
    "            else:\n",
    "                continue\n",
    "        pathway_ids = th.tensor(pathway_ids).long()\n",
    "        GPwy_ids = th.tensor(GPwy_ids)\n",
    "        html_ensemble_pathway, html_TransE_pathway, html_TransR_pathway, html_ComplEx_pathway, html_DistMult_pathway = \\\n",
    "            predict_triplets(target_id, pathway_ids, 'Pathway', GPwy_ids, top_k)\n",
    "\n",
    "        gene_tp_df = GG[(GG['Head'] == target_id) | (GG['Tail'] == target_id)]\n",
    "        gene_tp_list = list(set(list(gene_tp_df['Head']) + list(gene_tp_df['Tail'])))\n",
    "        gene_candidate_df = entity_df[(entity_df[1].str.contains('HGNC')) & (~entity_df[1].isin(gene_tp_list))]\n",
    "        gene_list = list(gene_candidate_df[1])\n",
    "        GG_rel = list(GG.drop_duplicates(subset='Relation', keep='first')['Relation'])\n",
    "        GG_ids = [relation_map[rel] for rel in GG_rel]\n",
    "        gene_ids = [entity_map[g] for g in gene_list]\n",
    "        gene_ids = th.tensor(gene_ids).long()\n",
    "        GG_ids = th.tensor(GG_ids)\n",
    "        html_ensemble_gene, html_TransE_gene, html_TransR_gene, html_ComplEx_gene, html_DistMult_gene = \\\n",
    "            predict_triplets(target_id, gene_ids, 'Gene', GG_ids, top_k, 'GG')\n",
    "\n",
    "        predict_res['Ensemble'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ensemble_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ensemble_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ensemble_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_ensemble_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransE'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransE_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransE_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransE_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_TransE_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransR'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransR_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransR_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransR_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_TransR_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['ComplEx'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ComplEx_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ComplEx_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ComplEx_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_ComplEx_pathway + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['DistMult'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_DistMult_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_DistMult_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_DistMult_disease + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Pathway</h2><div class='layui-colla-content'>\" + html_DistMult_pathway + \"</div></div></div>\"\n",
    "\n",
    "    elif target_type == 'Symptom':\n",
    "        target_id = symptom_name_dict[entity_name]\n",
    "        disease_tp_df = DiSy[DiSy['Tail'] == target_id]\n",
    "        disease_tp_list = list(disease_tp_df['Head'])\n",
    "        disease_candidate_df = entity_df[(entity_df[1].str.contains('DOID')) & (~entity_df[1].isin(disease_tp_list))]\n",
    "        disease_list = list(disease_candidate_df[1])\n",
    "        DiSy_rel = ['Present_DiSy']\n",
    "        DiSy_ids = [relation_map[rel] for rel in DiSy_rel]\n",
    "        disease_ids = [entity_map[g] for g in disease_list]\n",
    "        disease_ids = th.tensor(disease_ids).long()\n",
    "        DiSy_ids = th.tensor(DiSy_ids)\n",
    "        html_ensemble_disease, html_TransE_disease, html_TransR_disease, html_ComplEx_disease, html_DistMult_disease = \\\n",
    "            predict_triplets(target_id, disease_ids, 'Disease', DiSy_ids, top_k)\n",
    "\n",
    "        predict_res['Ensemble'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ensemble_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransE'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransE_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransR'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransR_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['ComplEx'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ComplEx_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['DistMult'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_DistMult_disease + \"</div></div></div>\"\n",
    "\n",
    "    elif target_type == 'Side_Effect':\n",
    "        target_id = se_name_dict[entity_name]\n",
    "        drug_tp_df = DSE[DSE['Tail'] == target_id]\n",
    "        drug_tp_list = list(drug_tp_df['Head'])\n",
    "        drug_candidate_df = entity_df[(entity_df[1].str.contains('DrugBank')) & (~entity_df[1].isin(drug_tp_list))]\n",
    "        drug_list = list(drug_candidate_df[1])\n",
    "        DSE_rel = ['Cause_DSE']\n",
    "        DSE_ids = [relation_map[rel] for rel in DSE_rel]\n",
    "        drug_ids = [entity_map[g] for g in drug_list]\n",
    "        drug_ids = th.tensor(drug_ids).long()\n",
    "        DSE_ids = th.tensor(DSE_ids)\n",
    "        html_ensemble_drug, html_TransE_drug, html_TransR_drug, html_ComplEx_drug, html_DistMult_drug = \\\n",
    "            predict_triplets(target_id, drug_ids, 'Drug', DSE_ids, top_k)\n",
    "\n",
    "        predict_res['Ensemble'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ensemble_drug + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransE'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransE_drug + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransR'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransR_drug + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['ComplEx'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ComplEx_drug + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['DistMult'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_DistMult_drug + \"</div></div></div>\"\n",
    "\n",
    "    elif target_type == 'Pathway':\n",
    "        target_id = pathway_name_dict[entity_name]\n",
    "        disease_tp_df = DiPwy[DiPwy['Tail'] == target_id]\n",
    "        disease_tp_list = list(disease_tp_df['Head'])\n",
    "        disease_candidate_df = entity_df[(entity_df[1].str.contains('DOID')) & (~entity_df[1].isin(disease_tp_list))]\n",
    "        disease_list = list(disease_candidate_df[1])\n",
    "        DiPwy_rel = ['Association_DiPwy']\n",
    "        DiPwy_ids = [relation_map[rel] for rel in DiPwy_rel]\n",
    "        disease_ids = [entity_map[g] for g in disease_list]\n",
    "        disease_ids = th.tensor(disease_ids).long()\n",
    "        DiPwy_ids = th.tensor(DiPwy_ids)\n",
    "        html_ensemble_disease, html_TransE_disease, html_TransR_disease, html_ComplEx_disease, html_DistMult_disease = \\\n",
    "            predict_triplets(target_id, disease_ids, 'Disease', DiPwy_ids, top_k)\n",
    "\n",
    "        drug_tp_df = DPwy[DPwy['Tail'] == target_id]\n",
    "        drug_tp_list = list(drug_tp_df['Head'])\n",
    "        drug_candidate_df = entity_df[(entity_df[1].str.contains('DrugBank')) & (~entity_df[1].isin(drug_tp_list))]\n",
    "        drug_list = list(drug_candidate_df[1])\n",
    "        DPwy_rel = ['Association_DiPwy']\n",
    "        DPwy_ids = [relation_map[rel] for rel in DPwy_rel]\n",
    "        drug_ids = [entity_map[g] for g in drug_list]\n",
    "        drug_ids = th.tensor(drug_ids).long()\n",
    "        DPwy_ids = th.tensor(DPwy_ids)\n",
    "        html_ensemble_drug, html_TransE_drug, html_TransR_drug, html_ComplEx_drug, html_DistMult_drug = \\\n",
    "            predict_triplets(target_id, drug_ids, 'Drug', DPwy_ids, top_k)\n",
    "\n",
    "        gene_tp_df = GPwy[GPwy['Tail'] == target_id]\n",
    "        gene_tp_list = list(gene_tp_df['Head'])\n",
    "        gene_candidate_df = entity_df[(entity_df[1].str.contains('HGNC')) & (~entity_df[1].isin(gene_tp_list))]\n",
    "        gene_list = list(gene_candidate_df[1])\n",
    "        GPwy_rel = ['Association_DiPwy']\n",
    "        GPwy_ids = [relation_map[rel] for rel in GPwy_rel]\n",
    "        gene_ids = [entity_map[g] for g in gene_list]\n",
    "        gene_ids = th.tensor(gene_ids).long()\n",
    "        GPwy_ids = th.tensor(GPwy_ids)\n",
    "        html_ensemble_gene, html_TransE_gene, html_TransR_gene, html_ComplEx_gene, html_DistMult_gene = \\\n",
    "            predict_triplets(target_id, gene_ids, 'Gene', GPwy_ids, top_k)\n",
    "\n",
    "        predict_res['Ensemble'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ensemble_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ensemble_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ensemble_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransE'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransE_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransE_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransE_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['TransR'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_TransR_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_TransR_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_TransR_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['ComplEx'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_ComplEx_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_ComplEx_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_ComplEx_disease + \"</div></div></div>\"\n",
    "\n",
    "        predict_res['DistMult'] = \"<div class='layui-collapse'>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Drug</h2><div class='layui-colla-content'>\" + html_DistMult_drug + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Gene</h2><div class='layui-colla-content'>\" + html_DistMult_gene + \"</div></div>\" \\\n",
    "                    \"<div class='layui-colla-item'><h2 class='layui-colla-title'>Disease</h2><div class='layui-colla-content'>\" + html_DistMult_disease + \"</div></div></div>\"\n",
    "\n",
    "    return predict_res, target_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example for discovering top 10 genes, drugs, symptoms, and pathways which potentially link to AD (Alzheimer's disease)\n",
    "\n",
    "entity_type = 'Disease'\n",
    "entity_name = \"alzheimer's disease\"\n",
    "topk = 10\n",
    "predict_res, entity_id = generate_predict_res(entity_type, entity_name, topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image/knowledge_discover.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
